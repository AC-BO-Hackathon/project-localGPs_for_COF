{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45452e9-567c-4658-bfa1-f9a6f6b70bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14747c8b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This file costructs surrogate models for the input datasets\n",
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed, dump\n",
    "\n",
    "# Torch specific module imports\n",
    "import torch\n",
    "import gpytorch \n",
    "\n",
    "# botorch specific modules\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from botorch.optim import optimize_acqf, optimize_acqf_discrete\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition.monte_carlo import (\n",
    "    qExpectedImprovement,\n",
    "    qNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.acquisition import UpperConfidenceBound, ExpectedImprovement\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Tick parameters\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['xtick.major.size'] = 5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.size'] = 5\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.size'] = 5\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 15\n",
    "\n",
    "# User defined python classes and files\n",
    "import input_class \n",
    "import code_inputs as model_input\n",
    "import utils_dataset as utilsd\n",
    "import surrogate_models\n",
    "import kmeans as km\n",
    "\n",
    "# Set the random seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29bdc5",
   "metadata": {},
   "source": [
    "#### K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8de62ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num carbon</th>\n",
       "      <th>num fluorine</th>\n",
       "      <th>num hydrogen</th>\n",
       "      <th>num nitrogen</th>\n",
       "      <th>num oxygen</th>\n",
       "      <th>num sulfur</th>\n",
       "      <th>num silicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69835</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69836</th>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69837</th>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69838</th>\n",
       "      <td>1888</td>\n",
       "      <td>0</td>\n",
       "      <td>1152</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69839</th>\n",
       "      <td>536</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69840 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num carbon  num fluorine  num hydrogen  num nitrogen  num oxygen  \\\n",
       "0             360             0           216           144          72   \n",
       "1             360             0           216           144         144   \n",
       "2             432             0           360           144          72   \n",
       "3             360             0           144           216         216   \n",
       "4             360             0           144           216         216   \n",
       "...           ...           ...           ...           ...         ...   \n",
       "69835         996             0           576            96           0   \n",
       "69836        1020             0           576            48           0   \n",
       "69837        1360             0           768            64           0   \n",
       "69838        1888             0          1152           128         128   \n",
       "69839         536             0           288            32           0   \n",
       "\n",
       "       num sulfur  num silicon  \n",
       "0               0            0  \n",
       "1               0            0  \n",
       "2               0            0  \n",
       "3               0            0  \n",
       "4               0            0  \n",
       "...           ...          ...  \n",
       "69835           0            0  \n",
       "69836           0            0  \n",
       "69837           0            0  \n",
       "69838           0            0  \n",
       "69839           0            0  \n",
       "\n",
       "[69840 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = input_class.inputs(input_path='../datasets/')\n",
    "XX_prop, YY, descriptors = Input.read_inputs()\n",
    "XX_comp_df, YY_df = Input.get_comp()\n",
    "XX_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe95ea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num carbon</th>\n",
       "      <th>num fluorine</th>\n",
       "      <th>num hydrogen</th>\n",
       "      <th>num nitrogen</th>\n",
       "      <th>num oxygen</th>\n",
       "      <th>num sulfur</th>\n",
       "      <th>num silicon</th>\n",
       "      <th>deliverable capacity [v STP/v]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "      <td>448</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.565439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1152</td>\n",
       "      <td>0</td>\n",
       "      <td>832</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152.524690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1376</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.996501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143.024802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153.528996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69835</th>\n",
       "      <td>1536</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.196985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69836</th>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>1368</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>137.095297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69837</th>\n",
       "      <td>2560</td>\n",
       "      <td>0</td>\n",
       "      <td>1536</td>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169.809763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69838</th>\n",
       "      <td>2784</td>\n",
       "      <td>0</td>\n",
       "      <td>1824</td>\n",
       "      <td>576</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.963253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69839</th>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>96</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.323232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69840 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num carbon  num fluorine  num hydrogen  num nitrogen  num oxygen  \\\n",
       "0             832             0           448           384           0   \n",
       "1            1152             0           832           128          64   \n",
       "2            1376             0           896           256          64   \n",
       "3             864             0           720           192           0   \n",
       "4            1088             0           768           128           0   \n",
       "...           ...           ...           ...           ...         ...   \n",
       "69835        1536             0           960           160           0   \n",
       "69836        1440             0          1368           216           0   \n",
       "69837        2560             0          1536           384         384   \n",
       "69838        2784             0          1824           576          96   \n",
       "69839        1920             0          1200            96          48   \n",
       "\n",
       "       num sulfur  num silicon  deliverable capacity [v STP/v]  \n",
       "0               0            0                      165.565439  \n",
       "1               0            0                      152.524690  \n",
       "2               0            0                      115.996501  \n",
       "3               0            0                      143.024802  \n",
       "4               0            0                      153.528996  \n",
       "...           ...          ...                             ...  \n",
       "69835           0            0                      110.196985  \n",
       "69836           0           36                      137.095297  \n",
       "69837           0            0                      169.809763  \n",
       "69838           0            0                      110.963253  \n",
       "69839           0            0                      166.323232  \n",
       "\n",
       "[69840 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_dfs = km.k_means(XX_comp_df, YY_df, model_input.NUM_CLUSTER)\n",
    "sample_dfs = km.draw_samples(clustered_dfs, sample_fraction = 1.00)\n",
    "samples = km.concat(sample_dfs)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed4601",
   "metadata": {},
   "source": [
    "#### Acquisition function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955bc734-96c5-4d3a-9325-920c041e256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: TO BE Check\n",
    "bounds = torch.tensor([[-10.0], [12.0]])\n",
    "\n",
    "batch_size = 1\n",
    "num_restarts= 10 \n",
    "raw_samples = 512\n",
    "\n",
    "def optimize_acqf_and_get_observation(acq_func, X_test, Y_test):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate\"\"\"\n",
    "    # print(X_test)\n",
    "    # print(Y_test)\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf_discrete(\n",
    "        acq_function=acq_func,\n",
    "        choices=X_test,\n",
    "        q=batch_size,\n",
    "        max_batch_size=2048,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "        unique=True\n",
    "    )\n",
    "    \n",
    "    print(candidates)\n",
    "    # observe new values\n",
    "    new_x = candidates.detach()\n",
    "    b = [1 if torch.all(X_test[i].eq(new_x)) else 0 for i in range(0,X_test.shape[0]) ]\n",
    "    b = torch.tensor(b).to(torch.int)\n",
    "    index = b.nonzero()[0][0]\n",
    "    new_y = torch.reshape(Y_test[0,index],(1,1))\n",
    "    \n",
    "    X_test_new = X_test[torch.arange(0, X_test.shape[0]) != index, ...]\n",
    "    Y_test_new = Y_test[..., torch.arange(0, Y_test.shape[1]) != index]\n",
    "    \n",
    "    return new_x, new_y, index, X_test_new, Y_test_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f668d",
   "metadata": {},
   "source": [
    "#### GP Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72bb9112-1749-44fd-bc9d-7c0edb2e59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(cluster_dataXX, cluster_dataYY, random_seed):\n",
    "    if model_input.STANDARDIZE:\n",
    "        cluster_dataXX, scalerX_transform = utilsd.standardize_data(cluster_dataXX)\n",
    "        cluster_dataYY, scalerY_transform = utilsd.standardize_data(cluster_dataYY.reshape(-1,1))\n",
    "    else:\n",
    "        scalerX_transform = None\n",
    "        scalerY_transform = None\n",
    "    \n",
    "    ## TODO : Incase for feature selection\n",
    "        # ....\n",
    "        # ....\n",
    "        # ....\n",
    "\n",
    "    # Create train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(cluster_dataXX, cluster_dataYY, test_size=model_input.TEST_SIZE, random_state=random_seed)\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    Y_train = np.transpose(Y_train) # IMP : Has to have only one row for GP training\n",
    "    Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "    Y_test = np.transpose(Y_test)\n",
    "    Y_test = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test, scalerX_transform, scalerY_transform\n",
    "\n",
    "def train_gp(X_train, X_test, Y_train, Y_test, model=None):\n",
    "    best_observed = []\n",
    "    # Finding best value in initial data\n",
    "    if model_input.MAXIMIZATION:\n",
    "        best_observed_value = Y_train.max()\n",
    "        optimal_solution = torch.cat([Y_train[0],Y_test[0]]).max()\n",
    "    else:\n",
    "        best_observed_value = Y_train.min()\n",
    "        optimal_solution = torch.cat([Y_train[0],Y_test[0]]).min()\n",
    "    \n",
    "    # If optimal value is present in the initial dataset sample remove it  \n",
    "    if (best_observed_value.eq(optimal_solution)) and model_input.MAXIMIZATION:\n",
    "        print('Max in training set, removing it before training models.')\n",
    "        optimal_position = torch.argmax(Y_train)\n",
    "        \n",
    "        # Add max value to test/exploration set\n",
    "        X_add_toTest = torch.reshape(X_train[optimal_position,:],(1,X_train.shape[1]))\n",
    "        X_test = torch.cat([X_test,X_add_toTest])\n",
    "        Y_add_toTest = torch.reshape(optimal_solution,(1,1))      \n",
    "        Y_test = torch.cat((Y_test,Y_add_toTest),1)\n",
    "        \n",
    "        # Remove max value from training set\n",
    "        X_train = X_train[torch.arange(0, X_train.shape[0]) != optimal_position, ...]\n",
    "        Y_train = Y_train[..., torch.arange(0, Y_train.shape[1]) != optimal_position]\n",
    "        \n",
    "        # Update best observed value\n",
    "        best_observed_value = Y_train.max()\n",
    "        \n",
    "    elif (best_observed_value.eq(optimal_solution)) and not model_input.MAXIMIZATION:\n",
    "        print('Min in training set, removing it before training models.')\n",
    "        optimal_position = torch.argmin(Y_train)\n",
    "        \n",
    "        # Add min value to test/exploration set\n",
    "        X_add_toTest = torch.reshape(X_train[optimal_position,:],(1,X_train.shape[1]))\n",
    "        X_test = torch.cat([X_test,X_add_toTest])\n",
    "        Y_add_toTest = torch.reshape(optimal_solution,(1,1))      \n",
    "        Y_test = torch.cat((Y_test,Y_add_toTest),1)\n",
    "        \n",
    "        # Remove min value from training set\n",
    "        X_train = X_train[torch.arange(0, X_train.shape[0]) != optimal_position, ...]\n",
    "        Y_train = Y_train[..., torch.arange(0, Y_train.shape[1]) != optimal_position]\n",
    "        \n",
    "        # Update best observed value\n",
    "        best_observed_value = Y_train.min()\n",
    "    \n",
    "    # Initialize data for training gp-0 and gp-l models\n",
    "    X_train0, Y_train0, X_test0, Y_test0 = X_train, Y_train, X_test, Y_test\n",
    "            \n",
    "    n_batch = int(model_input.N_BATCH_PER_TRIAL/model_input.N_SEARCH)\n",
    "    \n",
    "    # Initialize likelihood, GP model and acquisition function for the models\n",
    "    #--------------------------- GP-0 ---------------------------#\n",
    "    likelihood_gp0 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    if model is None:\n",
    "        model_gp0 = surrogate_models.ExactGPModel(X_train0, Y_train0, likelihood_gp0) \n",
    "    else:\n",
    "        model_gp0 = model\n",
    "    AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_observed_value, maximize=model_input.MAXIMIZATION)\n",
    "    best_observed.append(best_observed_value)  # Appending to best_observed list for the given trial\n",
    "    \n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, n_batch + 1):\n",
    "        # Time start of iteration and end\n",
    "        t0 = time.monotonic()\n",
    "        if ((iteration-1)%model_input.N_UPDATE==0):\n",
    "            # fit the models every 10 iterations\n",
    "            model_gp0, likelihood_gp0 = surrogate_models.train_surrogate_gp0(X_train0, Y_train0)\n",
    "    \n",
    "        # optimize and get new observation using acquisition function\n",
    "        new_x0, new_y0, index, X_test_new0, Y_test_new0 = optimize_acqf_and_get_observation(AcqFunc_0, X_test0, Y_test0)\n",
    "        \n",
    "        # Update remaining choices tensor\n",
    "        X_test0 = X_test_new0\n",
    "        Y_test0 = Y_test_new0\n",
    "\n",
    "        # Update training points\n",
    "        X_train0 = torch.cat([X_train0, new_x0])\n",
    "        Y_train0 = torch.cat([Y_train0[0], new_y0[0]])\n",
    "        Y_train0 = torch.reshape(Y_train0,(1,Y_train0.shape[0]))\n",
    "\n",
    "        # update progress\n",
    "        if model_input.MAXIMIZATION:\n",
    "            best_value_ei0 = Y_train0.max()\n",
    "        elif not model_input.MAXIMIZATION:\n",
    "            best_value_ei0 = Y_train0.min()\n",
    "        best_observed.append(best_value_ei0)\n",
    "\n",
    "        # AcqFunc_0 = UpperConfidenceBound(model_gp0, beta=0.1) \n",
    "        AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_value_ei0, maximize=model_input.MAXIMIZATION)\n",
    "\n",
    "        # Time end of iteration\n",
    "        t1 = time.monotonic()\n",
    "    \n",
    "        if model_input.VERBOSE:\n",
    "            print(\n",
    "                f\"\\nBatch {iteration:>2}: best_value (GP-0) = \",\n",
    "                f\"({best_value_ei0:>4.2f}\",\n",
    "                end=\"\",)\n",
    "            print(f'Iteration time = {t1-t0:>4.2f}.')\n",
    "\n",
    "    # t1 = time.monotonic()\n",
    "    # print(f\"time = {t1-t0:>4.2f}.\")\n",
    "\n",
    "    return [best_observed, X_train0, X_test0, Y_train0, Y_test0, model_gp0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbf21d",
   "metadata": {},
   "source": [
    "#### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfb03e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- Trial  1 of 1 --------------------\n",
      "(1, 3, 1)\n",
      "\n",
      " -------------------- Cluster  0 of 3 --------------------\n",
      "\n",
      " -------------------- Cluster  1 of 3 --------------------\n",
      "\n",
      " -------------------- Cluster  2 of 3 --------------------\n",
      "Using cpu deviceUsing cpu device\n",
      "\n",
      "Using cpu device\n",
      "tensor([[-0.6042, -0.0295, -0.7947,  1.3747,  1.5369, -0.0630, -0.1566]])\n",
      "\n",
      "Batch  1: best_value (GP-0) =  (1.92Iteration time = 1.61.\n",
      "tensor([[ 1.0603, -0.0367, -1.6548,  0.8714, -0.7460, -0.0717, -0.1818]])\n",
      "\n",
      "Batch  1: best_value (GP-0) =  (2.55Iteration time = 17.92.\n",
      "tensor([[-0.6552, -0.0414, -1.2317,  3.5658, -0.7353, -0.0663, -0.1789]])\n",
      "\n",
      "Batch  1: best_value (GP-0) =  (2.71Iteration time = 84.47.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Initially training of GPs done in parallel by using joblib\u001b[39;00m\n\u001b[1;32m     51\u001b[0m results_cluster_0, results_cluster_1, results_cluster_2 \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(delayed(train_gp)(X_train_all_clusters[i], X_test_all_clusters[i], Y_train_all_clusters[i], Y_test_all_clusters[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model_input\u001b[38;5;241m.\u001b[39mNUM_CLUSTER))\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, results_i_cluster \u001b[38;5;129;01min\u001b[39;00m [results_cluster_0, results_cluster_1, results_cluster_2]:\n\u001b[1;32m     54\u001b[0m     best_observed_all_clusters[trial\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][i][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mint\u001b[39m(model_input\u001b[38;5;241m.\u001b[39mN_BATCH_PER_TRIAL\u001b[38;5;241m/\u001b[39mmodel_input\u001b[38;5;241m.\u001b[39mN_SEARCH)] \u001b[38;5;241m=\u001b[39m results_i_cluster[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m     55\u001b[0m     X_train_all_clusters\u001b[38;5;241m.\u001b[39mappend(results_i_cluster[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Create a new directory if it does not exist\n",
    "isExist = os.path.exists(model_input.OUT_FOLDER)\n",
    "if not isExist:\n",
    "    os.makedirs(model_input.OUT_FOLDER)\n",
    "    print(\"The new directory is created!\", model_input.OUT_FOLDER)\n",
    "\n",
    "shutil.copy2('surrogate_models.py',model_input.OUT_FOLDER)\n",
    "\n",
    "# Train each GP model sequentially first then apply the epsilon greed algorithm\n",
    "for trial in range(1, model_input.N_TRIALS + 1):\n",
    "    t0 = time.monotonic()\n",
    "    if model_input.RANDOM_SEED == 'time':\n",
    "        random_seed = int(t0)\n",
    "    elif model_input.RANDOM_SEED == 'iteration':\n",
    "        random_seed = trial\n",
    "\n",
    "    print(f\"\\n -------------------- Trial {trial:>2} of {model_input.N_TRIALS} --------------------\\n\", end=\"\")\n",
    "\n",
    "    best_observed_all_clusters = np.zeros((model_input.N_TRIALS, model_input.NUM_CLUSTER, model_input.N_BATCH_PER_TRIAL))\n",
    "    print(best_observed_all_clusters.shape)\n",
    "    X_train_all_clusters = []\n",
    "    X_test_all_clusters = []\n",
    "    Y_train_all_clusters = []\n",
    "    Y_test_all_clusters = []\n",
    "    model_gps_all_clusters = []\n",
    "\n",
    "    # Creating the initial training and test sets for each cluster\n",
    "    for cluster_idx in range(model_input.NUM_CLUSTER):\n",
    "        print(f\"\\n -------------------- Cluster {cluster_idx:>2} of {model_input.NUM_CLUSTER} --------------------\\n\", end=\"\")\n",
    "        XX_desc = list(sample_dfs[cluster_idx].columns[:-1])\n",
    "        YY_desc = sample_dfs[cluster_idx].columns[-1]\n",
    "        (\n",
    "            X_train_idx,\n",
    "            X_test_idx,\n",
    "            Y_train_idx,\n",
    "            Y_test_idx,\n",
    "            scalerX, \n",
    "            scalerY\n",
    "        ) = create_train_test_data(sample_dfs[cluster_idx][XX_desc].to_numpy(), sample_dfs[cluster_idx][YY_desc].to_numpy(), random_seed)\n",
    "        dump(scalerX, os.path.join(model_input.OUT_FOLDER, f'scalerX_{cluster_idx}.joblib'))\n",
    "        dump(scalerY, os.path.join(model_input.OUT_FOLDER, f'scalerY_{cluster_idx}.joblib'))\n",
    "        X_train_all_clusters.append(X_train_idx)\n",
    "        X_test_all_clusters.append(X_test_idx)\n",
    "        Y_train_all_clusters.append(Y_train_idx)\n",
    "        Y_test_all_clusters.append(Y_test_idx)\n",
    "    \n",
    "    # Initially training of GPs done in parallel by using joblib\n",
    "    results_cluster_0, results_cluster_1, results_cluster_2 = Parallel(n_jobs=-1)(delayed(train_gp)(X_train_all_clusters[i], X_test_all_clusters[i], Y_train_all_clusters[i], Y_test_all_clusters[i]) for i in range(model_input.NUM_CLUSTER))\n",
    "\n",
    "    for i, results_i_cluster in [results_cluster_0, results_cluster_1, results_cluster_2]:\n",
    "        best_observed_all_clusters[trial-1][i][0:int(model_input.N_BATCH_PER_TRIAL/model_input.N_SEARCH)] = results_i_cluster[0] \n",
    "        X_train_all_clusters.append(results_i_cluster[1])\n",
    "        X_test_all_clusters.append(results_i_cluster[2])\n",
    "        Y_train_all_clusters.append(results_i_cluster[3])\n",
    "        Y_test_all_clusters.append(results_i_cluster[4])\n",
    "        model_gps_all_clusters.append(results_i_cluster[5])\n",
    "\n",
    "    # print(f'\\n')\n",
    "    # print(f'Starting the epsilon greedy search')\n",
    "    # print(f'\\n')    \n",
    "\n",
    "    # # Now apply the epsilon greedy algorithm and choose which GP to train next\n",
    "    # for i in range(model_input.N_SEARCH):\n",
    "    #     random_number = np.random.rand()\n",
    "    #     epsilon = model_input.EPSILON\n",
    "    #     # Explore using the Epsilon Greedy Exploration Strategy\n",
    "    #     if random_number <= epsilon:\n",
    "    #         # Selecting a number between 1,2 and 3\n",
    "    #         cluster_idx = np.random.choice(model_input.NUM_CLUSTER)\n",
    "    #     else:\n",
    "    #         # Exploit best known action\n",
    "    #         cluster_idx = np.argmax(best_observed_all_clusters[i][-1] for i in range(model_input.NUM_CLUSTER))\n",
    "    #     print(f'Iteration {i} : Cluster {cluster_idx} is selected for training')\n",
    "    #     results = train_gp(X_train_all_clusters[cluster_idx], \\\n",
    "    #                        X_test_all_clusters[cluster_idx], \\\n",
    "    #                        Y_train_all_clusters[cluster_idx], \\\n",
    "    #                        Y_test_all_clusters[cluster_idx], \\\n",
    "    #                        model=model_gps_all_clusters[cluster_idx])\n",
    "        \n",
    "    #     # Add the best values\n",
    "    #     best_observed_all_clusters[cluster_idx].extend(best_observed_idx)\n",
    "    #     X_train_all_clusters[cluster_idx] = results[1]\n",
    "    #     X_test_all_clusters[cluster_idx] = results[2]\n",
    "    #     Y_train_all_clusters[cluster_idx] = results[3]\n",
    "    #     Y_test_all_clusters[cluster_idx] = results[4]\n",
    "    #     model_gps_all_clusters[cluster_idx] = results[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04617178",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2,) into shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, results_i_cluster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([results_cluster_0, results_cluster_1, results_cluster_2]):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mbest_observed_all_clusters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_BATCH_PER_TRIAL\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mN_SEARCH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m results_i_cluster[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m      3\u001b[0m     X_train_all_clusters\u001b[38;5;241m.\u001b[39mappend(results_i_cluster[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      4\u001b[0m     X_test_all_clusters\u001b[38;5;241m.\u001b[39mappend(results_i_cluster[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2,) into shape (1,)"
     ]
    }
   ],
   "source": [
    "for i, results_i_cluster in enumerate([results_cluster_0, results_cluster_1, results_cluster_2]):\n",
    "    best_observed_all_clusters[trial-1][i][0:int(model_input.N_BATCH_PER_TRIAL/model_input.N_SEARCH)] = results_i_cluster[0] \n",
    "    X_train_all_clusters.append(results_i_cluster[1])\n",
    "    X_test_all_clusters.append(results_i_cluster[2])\n",
    "    Y_train_all_clusters.append(results_i_cluster[3])\n",
    "    Y_test_all_clusters.append(results_i_cluster[4])\n",
    "    model_gps_all_clusters.append(results_i_cluster[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad1511ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0.]\n",
      "  [1. 2. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "l = np.zeros((3,3,4))\n",
    "\n",
    "l[0][1][0:2] = [1,2]\n",
    "\n",
    "print(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a686cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best value obtained vs number of iterations\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(model_input.NUM_CLUSTER):\n",
    "    plt.plot(best_observed_all_clusters[i], label=f'Cluster {i}')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Best Value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
