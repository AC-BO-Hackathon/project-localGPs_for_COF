{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45452e9-567c-4658-bfa1-f9a6f6b70bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14a380850>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This file costructs surrogate models for the input datasets\n",
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed, dump\n",
    "\n",
    "# Torch specific module imports\n",
    "import torch\n",
    "import gpytorch \n",
    "\n",
    "# botorch specific modules\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from botorch.optim import optimize_acqf, optimize_acqf_discrete\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition.monte_carlo import (\n",
    "    qExpectedImprovement,\n",
    "    qNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.acquisition import UpperConfidenceBound, ExpectedImprovement\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Tick parameters\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['xtick.major.size'] = 5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.size'] = 5\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.size'] = 5\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 15\n",
    "\n",
    "# User defined python classes and files\n",
    "import input_class \n",
    "import code_inputs as model_input\n",
    "import utils_dataset as utilsd\n",
    "import surrogate_models\n",
    "import kmeans as km\n",
    "\n",
    "# Set the random seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29bdc5",
   "metadata": {},
   "source": [
    "#### K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8de62ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dimensions',\n",
       " ' bond type',\n",
       " ' void fraction [widom]',\n",
       " ' supercell volume [A^3]',\n",
       " ' density [kg/m^3]',\n",
       " ' heat desorption high P [kJ/mol]',\n",
       " ' absolute methane uptake high P [molec/unit cell]',\n",
       " ' absolute methane uptake high P [mol/kg]',\n",
       " ' excess methane uptake high P [molec/unit cell]',\n",
       " ' excess methane uptake high P [mol/kg]',\n",
       " ' heat desorption low P [kJ/mol]',\n",
       " ' absolute methane uptake low P [molec/unit cell]',\n",
       " ' absolute methane uptake low P [mol/kg]',\n",
       " ' excess methane uptake low P [molec/unit cell]',\n",
       " ' excess methane uptake low P [mol/kg]',\n",
       " ' surface area [m^2/g]',\n",
       " ' linkerA',\n",
       " ' linkerB',\n",
       " ' net',\n",
       " ' cell_a [A]',\n",
       " ' cell_b [A]',\n",
       " ' cell_c [A]',\n",
       " ' alpha [deg]',\n",
       " ' beta [deg]',\n",
       " ' gamma [deg]',\n",
       " ' num carbon',\n",
       " ' num fluorine',\n",
       " ' num hydrogen',\n",
       " ' num nitrogen',\n",
       " ' num oxygen',\n",
       " ' num sulfur',\n",
       " ' num silicon',\n",
       " ' vertices',\n",
       " ' edges',\n",
       " ' genus',\n",
       " ' largest included sphere diameter [A]',\n",
       " ' largest free sphere diameter [A]',\n",
       " ' largest included sphere along free sphere path diameter [A]',\n",
       " ' absolute methane uptake high P [v STP/v]',\n",
       " ' absolute methane uptake low P [v STP/v]']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = input_class.inputs(input_path='../')\n",
    "XX_prop, YY, descriptors = Input.read_inputs()\n",
    "descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147caa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num carbon</th>\n",
       "      <th>num fluorine</th>\n",
       "      <th>num hydrogen</th>\n",
       "      <th>num nitrogen</th>\n",
       "      <th>num oxygen</th>\n",
       "      <th>num sulfur</th>\n",
       "      <th>num silicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69835</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69836</th>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69837</th>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69838</th>\n",
       "      <td>1888</td>\n",
       "      <td>0</td>\n",
       "      <td>1152</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69839</th>\n",
       "      <td>536</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69840 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num carbon  num fluorine  num hydrogen  num nitrogen  num oxygen  \\\n",
       "0             360             0           216           144          72   \n",
       "1             360             0           216           144         144   \n",
       "2             432             0           360           144          72   \n",
       "3             360             0           144           216         216   \n",
       "4             360             0           144           216         216   \n",
       "...           ...           ...           ...           ...         ...   \n",
       "69835         996             0           576            96           0   \n",
       "69836        1020             0           576            48           0   \n",
       "69837        1360             0           768            64           0   \n",
       "69838        1888             0          1152           128         128   \n",
       "69839         536             0           288            32           0   \n",
       "\n",
       "       num sulfur  num silicon  \n",
       "0               0            0  \n",
       "1               0            0  \n",
       "2               0            0  \n",
       "3               0            0  \n",
       "4               0            0  \n",
       "...           ...          ...  \n",
       "69835           0            0  \n",
       "69836           0            0  \n",
       "69837           0            0  \n",
       "69838           0            0  \n",
       "69839           0            0  \n",
       "\n",
       "[69840 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX_comp_df, YY_df = Input.get_comp()\n",
    "XX_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe95ea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num carbon</th>\n",
       "      <th>num fluorine</th>\n",
       "      <th>num hydrogen</th>\n",
       "      <th>num nitrogen</th>\n",
       "      <th>num oxygen</th>\n",
       "      <th>num sulfur</th>\n",
       "      <th>num silicon</th>\n",
       "      <th>deliverable capacity [v STP/v]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "      <td>448</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.565439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1152</td>\n",
       "      <td>0</td>\n",
       "      <td>832</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152.524690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1376</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.996501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143.024802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153.528996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>288</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116.161354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>1024</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152.702060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>1536</td>\n",
       "      <td>0</td>\n",
       "      <td>1440</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.338457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>1104</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135.714021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1536</td>\n",
       "      <td>0</td>\n",
       "      <td>1152</td>\n",
       "      <td>768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133.680986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>697 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num carbon  num fluorine  num hydrogen  num nitrogen  num oxygen  \\\n",
       "0           832             0           448           384           0   \n",
       "1          1152             0           832           128          64   \n",
       "2          1376             0           896           256          64   \n",
       "3           864             0           720           192           0   \n",
       "4          1088             0           768           128           0   \n",
       "..          ...           ...           ...           ...         ...   \n",
       "692        1968             0          1200           288          48   \n",
       "693        2048             0          1024           640           0   \n",
       "694        1536             0          1440           384           0   \n",
       "695        1440             0          1104           384           0   \n",
       "696        1536             0          1152           768           0   \n",
       "\n",
       "     num sulfur  num silicon  deliverable capacity [v STP/v]  \n",
       "0             0            0                      165.565439  \n",
       "1             0            0                      152.524690  \n",
       "2             0            0                      115.996501  \n",
       "3             0            0                      143.024802  \n",
       "4             0            0                      153.528996  \n",
       "..          ...          ...                             ...  \n",
       "692           0            0                      116.161354  \n",
       "693           0            0                      152.702060  \n",
       "694           0            0                       99.338457  \n",
       "695           0            0                      135.714021  \n",
       "696           0            0                      133.680986  \n",
       "\n",
       "[697 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cluster = 3\n",
    "clustered_dfs = km.k_means(XX_comp_df, YY_df, num_cluster)\n",
    "sample_dfs = km.draw_samples(clustered_dfs, sample_fraction = 0.01)\n",
    "samples = km.concat(sample_dfs)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed4601",
   "metadata": {},
   "source": [
    "#### Acquisition function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "955bc734-96c5-4d3a-9325-920c041e256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: TO BE Check\n",
    "bounds = torch.tensor([[-10.0], [12.0]])\n",
    "\n",
    "batch_size = 1\n",
    "num_restarts= 10 \n",
    "raw_samples = 512\n",
    "\n",
    "def optimize_acqf_and_get_observation(acq_func, X_test, Y_test):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate\"\"\"\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf_discrete(\n",
    "        acq_function=acq_func,\n",
    "        choices=X_test,\n",
    "        q=batch_size,\n",
    "        max_batch_size=2048,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "        unique=True\n",
    "    )\n",
    "    \n",
    "    print(candidates)\n",
    "    # observe new values\n",
    "    new_x = candidates.detach()\n",
    "    b = [1 if torch.all(X_test[i].eq(new_x)) else 0 for i in range(0,X_test.shape[0]) ]\n",
    "    b = torch.tensor(b).to(torch.int)\n",
    "    index = b.nonzero()[0][0]\n",
    "    new_y = torch.reshape(Y_test[0,index],(1,1))\n",
    "    \n",
    "    X_test_new = X_test[torch.arange(0, X_test.shape[0]) != index, ...]\n",
    "    Y_test_new = Y_test[..., torch.arange(0, Y_test.shape[1]) != index]\n",
    "    print(X_test_new)\n",
    "    print(Y_test_new)\n",
    "    \n",
    "    return new_x, new_y, index, X_test_new, Y_test_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f668d",
   "metadata": {},
   "source": [
    "#### GP Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72bb9112-1749-44fd-bc9d-7c0edb2e59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(cluster_dataXX, cluster_dataYY, random_seed):\n",
    "    if model_input.standardize_data:\n",
    "        cluster_dataXX, scalerX_transform = utilsd.standardize_data(cluster_dataXX)\n",
    "        cluster_dataYY, scalerY_transform = utilsd.standardize_data(cluster_dataYY.reshape(-1,1))\n",
    "    else:\n",
    "        scalerX_transform = None\n",
    "        scalerY_transform = None\n",
    "    \n",
    "    ## TODO : Incase for feature selection\n",
    "        # ....\n",
    "        # ....\n",
    "        # ....\n",
    "\n",
    "    # Create train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(cluster_dataXX, cluster_dataYY, test_size=model_input.test_size, random_state=random_seed)\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    Y_train = np.transpose(Y_train) # IMP : Has to have only one row for GP training\n",
    "    Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "    Y_test = np.transpose(Y_test)\n",
    "    Y_test = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test, scalerX_transform, scalerY_transform\n",
    "\n",
    "def train_gp(cluster_idx):\n",
    "    best_observed_all_ei0 = []\n",
    "    # Average over multiple trials\n",
    "    for trial in range(1, model_input.n_trials + 1):\n",
    "        t0 = time.monotonic()\n",
    "        if model_input.random_seed == 'time':\n",
    "            random_seed = int(t0)\n",
    "        elif model_input.random_seed == 'iteration':\n",
    "            random_seed = trial\n",
    "            \n",
    "        print(f\"\\n -------------------- Trial {trial:>2} of {model_input.n_trials} --------------------\\n\", end=\"\")\n",
    "        best_observed0 = []\n",
    "\n",
    "        XX_desc = list(sample_dfs[cluster_idx].columns[:-1])\n",
    "        YY_desc = sample_dfs[cluster_idx].columns[-1]\n",
    "        (\n",
    "            X_train,\n",
    "            X_test,\n",
    "            Y_train,\n",
    "            Y_test,\n",
    "            scalerX, \n",
    "            scalerY\n",
    "        ) = create_train_test_data(sample_dfs[cluster_idx][XX_desc].to_numpy(), sample_dfs[cluster_idx][YY_desc].to_numpy(), random_seed)\n",
    "        if trial == 1:\n",
    "            # Dump the scalers to model output folder\n",
    "            dump(scalerX, os.path.join(model_input.output_folder, f'scalerX_{cluster_idx}.joblib'))\n",
    "            dump(scalerY, os.path.join(model_input.output_folder, f'scalerY_{cluster_idx}.joblib'))\n",
    "            \n",
    "        # Finding best value in initial data\n",
    "        if model_input.maximization:\n",
    "            best_observed_value = Y_train.max()\n",
    "            optimal_solution = torch.cat([Y_train[0],Y_test[0]]).max()\n",
    "        else:\n",
    "            best_observed_value = Y_train.min()\n",
    "            optimal_solution = torch.cat([Y_train[0],Y_test[0]]).min()\n",
    "        \n",
    "        # If optimal value is present in the initial dataset sample remove it  \n",
    "        if (best_observed_value.eq(optimal_solution)) and model_input.maximization:\n",
    "            print('Max in training set, removing it before training models.')\n",
    "            optimal_position = torch.argmax(Y_train)\n",
    "            \n",
    "            # Add max value to test/exploration set\n",
    "            X_add_toTest = torch.reshape(X_train[optimal_position,:],(1,X_train.shape[1]))\n",
    "            X_test = torch.cat([X_test,X_add_toTest])\n",
    "            Y_add_toTest = torch.reshape(optimal_solution,(1,1))      \n",
    "            Y_test = torch.cat((Y_test,Y_add_toTest),1)\n",
    "            \n",
    "            # Remove max value from training set\n",
    "            X_train = X_train[torch.arange(0, X_train.shape[0]) != optimal_position, ...]\n",
    "            Y_train = Y_train[..., torch.arange(0, Y_train.shape[1]) != optimal_position]\n",
    "            \n",
    "            # Update best observed value\n",
    "            best_observed_value = Y_train.max()\n",
    "            \n",
    "        elif (best_observed_value.eq(optimal_solution)) and not model_input.maximization:\n",
    "            print('Min in training set, removing it before training models.')\n",
    "            optimal_position = torch.argmin(Y_train)\n",
    "            \n",
    "            # Add min value to test/exploration set\n",
    "            X_add_toTest = torch.reshape(X_train[optimal_position,:],(1,X_train.shape[1]))\n",
    "            X_test = torch.cat([X_test,X_add_toTest])\n",
    "            Y_add_toTest = torch.reshape(optimal_solution,(1,1))      \n",
    "            Y_test = torch.cat((Y_test,Y_add_toTest),1)\n",
    "            \n",
    "            # Remove min value from training set\n",
    "            X_train = X_train[torch.arange(0, X_train.shape[0]) != optimal_position, ...]\n",
    "            Y_train = Y_train[..., torch.arange(0, Y_train.shape[1]) != optimal_position]\n",
    "            \n",
    "            # Update best observed value\n",
    "            best_observed_value = Y_train.min()\n",
    "        \n",
    "        # Initialize data for training gp-0 and gp-l models\n",
    "        X_train0, Y_train0, X_test0, Y_test0 = X_train, Y_train, X_test, Y_test\n",
    "                \n",
    "        n_batch = model_input.n_batch_perTrial\n",
    "        \n",
    "        # Initialize likelihood, GP model and acquisition function for the models\n",
    "        #--------------------------- GP-0 ---------------------------#\n",
    "        likelihood_gp0 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model_gp0 = surrogate_models.ExactGPModel(X_train0, Y_train0, likelihood_gp0)           \n",
    "        # AcqFunc_0 = UpperConfidenceBound(model_gp0, beta=0.1) \n",
    "        AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_observed_value, maximize=model_input.maximization)\n",
    "        best_observed0.append(best_observed_value)  # Appending to best_observed list for the given trial\n",
    "        \n",
    "        # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "        for iteration in range(1, n_batch + 1):\n",
    "\n",
    "            if ((iteration-1)%model_input.n_update==0):\n",
    "                # fit the models every 10 iterations\n",
    "                model_gp0, likelihood_gp0 = surrogate_models.train_surrogate_gp0(X_train0, Y_train0)\n",
    "        \n",
    "            # optimize and get new observation using acquisition function\n",
    "            new_x0, new_y0, index, X_test_new0, Y_test_new0 = optimize_acqf_and_get_observation(AcqFunc_0, X_test0, Y_test0)\n",
    "            \n",
    "            # Update remaining choices tensor\n",
    "            X_test0 = X_test_new0\n",
    "            Y_test0 = Y_test_new0\n",
    "\n",
    "            # Update training points\n",
    "            X_train0 = torch.cat([X_train0, new_x0])\n",
    "            Y_train0 = torch.cat([Y_train0[0], new_y0[0]])\n",
    "            Y_train0 = torch.reshape(Y_train0,(1,Y_train0.shape[0]))\n",
    "\n",
    "            # update progress\n",
    "            if model_input.maximization:\n",
    "                best_value_ei0 = Y_train0.max()\n",
    "            elif not model_input.maximization:\n",
    "                best_value_ei0 = Y_train0.min()\n",
    "            best_observed0.append(best_value_ei0)\n",
    "\n",
    "            # AcqFunc_0 = UpperConfidenceBound(model_gp0, beta=0.1) \n",
    "            AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_value_ei0, maximize=model_input.maximization)\n",
    "        \n",
    "            if model_input.verbose:\n",
    "                print(\n",
    "                    f\"\\nBatch {iteration:>2}: best_value (GP-0) = \",\n",
    "                    f\"({best_value_ei0:>4.2f}\",\n",
    "                    end=\"\",)\n",
    "\n",
    "        t1 = time.monotonic()\n",
    "        \n",
    "        print(f\"time = {t1-t0:>4.2f}.\")\n",
    "        # Appending to common list of best observed values, with number of rows equal to number of trials\n",
    "        best_observed_all_ei0.append(best_observed0) \n",
    "    return best_observed_all_ei0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbf21d",
   "metadata": {},
   "source": [
    "#### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb03e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Using cpu device\n",
      "Using cpu device\n",
      "\n",
      " -------------------- Trial  1 of 5 --------------------\n",
      "\n",
      " -------------------- Trial  1 of 5 --------------------\n",
      "\n",
      " -------------------- Trial  1 of 5 --------------------\n",
      "Max in training set, removing it before training models.\n",
      "Max in training set, removing it before training models.Max in training set, removing it before training models.\n",
      "\n",
      "tensor([[-0.8793,  0.0000, -0.7922,  1.8256, -0.5337, -0.1508, -0.1508]])\n",
      "tensor([[-0.4935,  0.0000, -1.7229, -0.7278,  0.7059, -0.1508, -0.1508]])\n",
      "tensor([[-1.0916]])\n",
      "\n",
      "Batch  1: best_value (GP-0) =  (1.79tensor([[-0.4935,  0.0000, -1.7229, -0.7278,  0.7059, -0.1508, -0.1508]])\n",
      "tensor([], size=(0, 7))\n",
      "tensor([], size=(1, 0))\n",
      "\n",
      "Batch  2: best_value (GP-0) =  (1.79"
     ]
    },
    {
     "ename": "InputDataError",
     "evalue": "`choices` must be non-emtpy.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/nikhilthota/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/Users/nikhilthota/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nikhilthota/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/k2/lw7ggcln7zx_cnkbk2zbgvm80000gn/T/ipykernel_16086/3447261974.py\", line 119, in train_gp\n  File \"/var/folders/k2/lw7ggcln7zx_cnkbk2zbgvm80000gn/T/ipykernel_16086/1975869805.py\", line 11, in optimize_acqf_and_get_observation\n  File \"/Users/nikhilthota/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/botorch/optim/optimize.py\", line 1053, in optimize_acqf_discrete\n    raise InputDataError(\"`choices` must be non-emtpy.\")\nbotorch.exceptions.errors.InputDataError: `choices` must be non-emtpy.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInputDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m shutil\u001b[38;5;241m.\u001b[39mcopy2(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogate_models.py\u001b[39m\u001b[38;5;124m'\u001b[39m,model_input\u001b[38;5;241m.\u001b[39moutput_folder)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Training a single GP for test\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# a = train_gp(0)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train the cluster of GP models in a parallel for loop\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m best_observed_all_ei0 \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_cluster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mInputDataError\u001b[0m: `choices` must be non-emtpy."
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Create a new directory if it does not exist\n",
    "isExist = os.path.exists(model_input.output_folder)\n",
    "if not isExist:\n",
    "    os.makedirs(model_input.output_folder)\n",
    "    print(\"The new directory is created!\", model_input.output_folder)\n",
    "    \n",
    "# Commented out by NKT\n",
    "# # Copy input parameters file to output folder\n",
    "# shutil.copy2('surrogate_model_inputs.py',model_input.output_folder)\n",
    "# Copy surrogate model file to output folder\n",
    "shutil.copy2('surrogate_models.py',model_input.output_folder)\n",
    "\n",
    "# Training a single GP for test\n",
    "# a = train_gp(0)\n",
    "\n",
    "# Train the cluster of GP models in a parallel for loop\n",
    "best_observed_all_ei0 = Parallel(n_jobs=-1)(\n",
    "    delayed(train_gp)(i) for i in range(num_cluster)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddae264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
