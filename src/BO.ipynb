{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45452e9-567c-4658-bfa1-f9a6f6b70bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15b284550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This file costructs surrogate models for the input datasets\n",
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed, dump\n",
    "\n",
    "# Torch specific module imports\n",
    "import torch\n",
    "import gpytorch \n",
    "\n",
    "# botorch specific modules\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from botorch.optim import optimize_acqf, optimize_acqf_discrete\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition.monte_carlo import (\n",
    "    qExpectedImprovement,\n",
    "    qNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.acquisition import UpperConfidenceBound, ExpectedImprovement\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Tick parameters\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['xtick.major.size'] = 5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.size'] = 5\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.size'] = 5\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 15\n",
    "\n",
    "# User defined python classes and files\n",
    "import input_class \n",
    "import code_inputs as model_input\n",
    "import utils_dataset as utilsd\n",
    "import surrogate_models\n",
    "import kmeans as km\n",
    "\n",
    "# Set the random seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29bdc5",
   "metadata": {},
   "source": [
    "#### K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8de62ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dimensions',\n",
       " ' bond type',\n",
       " ' void fraction [widom]',\n",
       " ' supercell volume [A^3]',\n",
       " ' density [kg/m^3]',\n",
       " ' heat desorption high P [kJ/mol]',\n",
       " ' absolute methane uptake high P [molec/unit cell]',\n",
       " ' absolute methane uptake high P [mol/kg]',\n",
       " ' excess methane uptake high P [molec/unit cell]',\n",
       " ' excess methane uptake high P [mol/kg]',\n",
       " ' heat desorption low P [kJ/mol]',\n",
       " ' absolute methane uptake low P [molec/unit cell]',\n",
       " ' absolute methane uptake low P [mol/kg]',\n",
       " ' excess methane uptake low P [molec/unit cell]',\n",
       " ' excess methane uptake low P [mol/kg]',\n",
       " ' surface area [m^2/g]',\n",
       " ' linkerA',\n",
       " ' linkerB',\n",
       " ' net',\n",
       " ' cell_a [A]',\n",
       " ' cell_b [A]',\n",
       " ' cell_c [A]',\n",
       " ' alpha [deg]',\n",
       " ' beta [deg]',\n",
       " ' gamma [deg]',\n",
       " ' num carbon',\n",
       " ' num fluorine',\n",
       " ' num hydrogen',\n",
       " ' num nitrogen',\n",
       " ' num oxygen',\n",
       " ' num sulfur',\n",
       " ' num silicon',\n",
       " ' vertices',\n",
       " ' edges',\n",
       " ' genus',\n",
       " ' largest included sphere diameter [A]',\n",
       " ' largest free sphere diameter [A]',\n",
       " ' largest included sphere along free sphere path diameter [A]',\n",
       " ' absolute methane uptake high P [v STP/v]',\n",
       " ' absolute methane uptake low P [v STP/v]']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = input_class.inputs(input_path='../')\n",
    "XX_prop, YY, descriptors = Input.read_inputs()\n",
    "descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147caa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num carbon</th>\n",
       "      <th>num fluorine</th>\n",
       "      <th>num hydrogen</th>\n",
       "      <th>num nitrogen</th>\n",
       "      <th>num oxygen</th>\n",
       "      <th>num sulfur</th>\n",
       "      <th>num silicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69835</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69836</th>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69837</th>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69838</th>\n",
       "      <td>1888</td>\n",
       "      <td>0</td>\n",
       "      <td>1152</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69839</th>\n",
       "      <td>536</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69840 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num carbon  num fluorine  num hydrogen  num nitrogen  num oxygen  \\\n",
       "0             360             0           216           144          72   \n",
       "1             360             0           216           144         144   \n",
       "2             432             0           360           144          72   \n",
       "3             360             0           144           216         216   \n",
       "4             360             0           144           216         216   \n",
       "...           ...           ...           ...           ...         ...   \n",
       "69835         996             0           576            96           0   \n",
       "69836        1020             0           576            48           0   \n",
       "69837        1360             0           768            64           0   \n",
       "69838        1888             0          1152           128         128   \n",
       "69839         536             0           288            32           0   \n",
       "\n",
       "       num sulfur  num silicon  \n",
       "0               0            0  \n",
       "1               0            0  \n",
       "2               0            0  \n",
       "3               0            0  \n",
       "4               0            0  \n",
       "...           ...          ...  \n",
       "69835           0            0  \n",
       "69836           0            0  \n",
       "69837           0            0  \n",
       "69838           0            0  \n",
       "69839           0            0  \n",
       "\n",
       "[69840 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX_comp_df, YY_df = Input.get_comp()\n",
    "XX_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe95ea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num carbon</th>\n",
       "      <th>num fluorine</th>\n",
       "      <th>num hydrogen</th>\n",
       "      <th>num nitrogen</th>\n",
       "      <th>num oxygen</th>\n",
       "      <th>num sulfur</th>\n",
       "      <th>num silicon</th>\n",
       "      <th>deliverable capacity [v STP/v]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118.707728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.133088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137.350112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92.034339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>936</td>\n",
       "      <td>0</td>\n",
       "      <td>648</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147.296600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69835</th>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143.719775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69836</th>\n",
       "      <td>1504</td>\n",
       "      <td>0</td>\n",
       "      <td>1280</td>\n",
       "      <td>256</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101.241397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69837</th>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>544</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.661907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69838</th>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132.487553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69839</th>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>36</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113.547143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69840 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num carbon  num fluorine  num hydrogen  num nitrogen  num oxygen  \\\n",
       "0             246             0           156            36          24   \n",
       "1             576             0           512           128           0   \n",
       "2             656             0           320            64          64   \n",
       "3             576             0           360             0           0   \n",
       "4             936             0           648           144           0   \n",
       "...           ...           ...           ...           ...         ...   \n",
       "69835        1248             0           576           320           0   \n",
       "69836        1504             0          1280           256         192   \n",
       "69837         752             0           544           160           0   \n",
       "69838         440             0           320            64          64   \n",
       "69839         504             0           288            36          72   \n",
       "\n",
       "       num sulfur  num silicon  deliverable capacity [v STP/v]  \n",
       "0               0            0                      118.707728  \n",
       "1               0            0                      170.133088  \n",
       "2               0            0                      137.350112  \n",
       "3               0            0                       92.034339  \n",
       "4               0            0                      147.296600  \n",
       "...           ...          ...                             ...  \n",
       "69835           0            0                      143.719775  \n",
       "69836           0            0                      101.241397  \n",
       "69837           0            0                      105.661907  \n",
       "69838           0            0                      132.487553  \n",
       "69839           0            0                      113.547143  \n",
       "\n",
       "[69840 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cluster = 1\n",
    "clustered_dfs = km.k_means(XX_comp_df, YY_df, num_cluster)\n",
    "sample_dfs = km.draw_samples(clustered_dfs, sample_fraction = 1.00)\n",
    "samples = km.concat(sample_dfs)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d105025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246   0 156 ...  24   0   0]\n",
      " [576   0 512 ...   0   0   0]\n",
      " [656   0 320 ...  64   0   0]\n",
      " ...\n",
      " [752   0 544 ...   0   0   0]\n",
      " [440   0 320 ...  64   0   0]\n",
      " [504   0 288 ...  72   0   0]]\n",
      "\n",
      "\n",
      "[118.70772784 170.13308797 137.35011199 ... 105.66190747 132.48755321\n",
      " 113.54714269]\n"
     ]
    }
   ],
   "source": [
    "cluster_idx = 0\n",
    "XX_desc = list(sample_dfs[cluster_idx].columns[:-1])\n",
    "YY_desc = sample_dfs[cluster_idx].columns[-1]\n",
    "print(sample_dfs[cluster_idx][XX_desc].to_numpy())\n",
    "print('\\n')\n",
    "print(sample_dfs[cluster_idx][YY_desc].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed4601",
   "metadata": {},
   "source": [
    "#### Acquisition function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "955bc734-96c5-4d3a-9325-920c041e256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: TO BE Check\n",
    "bounds = torch.tensor([[-10.0], [12.0]])\n",
    "\n",
    "batch_size = 1\n",
    "num_restarts= 10 \n",
    "raw_samples = 512\n",
    "\n",
    "def optimize_acqf_and_get_observation(acq_func, X_test, Y_test):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate\"\"\"\n",
    "    # print(X_test)\n",
    "    # print(Y_test)\n",
    "    # optimize\n",
    "    candidates, _ = optimize_acqf_discrete(\n",
    "        acq_function=acq_func,\n",
    "        choices=X_test,\n",
    "        q=batch_size,\n",
    "        max_batch_size=2048,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "        unique=True\n",
    "    )\n",
    "    \n",
    "    print(candidates)\n",
    "    # observe new values\n",
    "    new_x = candidates.detach()\n",
    "    b = [1 if torch.all(X_test[i].eq(new_x)) else 0 for i in range(0,X_test.shape[0]) ]\n",
    "    b = torch.tensor(b).to(torch.int)\n",
    "    index = b.nonzero()[0][0]\n",
    "    new_y = torch.reshape(Y_test[0,index],(1,1))\n",
    "    \n",
    "    X_test_new = X_test[torch.arange(0, X_test.shape[0]) != index, ...]\n",
    "    Y_test_new = Y_test[..., torch.arange(0, Y_test.shape[1]) != index]\n",
    "    # X_test_new = X_test\n",
    "    # Y_test_new = Y_test\n",
    "    print(X_test_new)\n",
    "    print(Y_test_new)\n",
    "    \n",
    "    return new_x, new_y, index, X_test_new, Y_test_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f668d",
   "metadata": {},
   "source": [
    "#### GP Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72bb9112-1749-44fd-bc9d-7c0edb2e59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(cluster_dataXX, cluster_dataYY, random_seed):\n",
    "    if model_input.standardize_data:\n",
    "        cluster_dataXX, scalerX_transform = utilsd.standardize_data(cluster_dataXX)\n",
    "        cluster_dataYY, scalerY_transform = utilsd.standardize_data(cluster_dataYY.reshape(-1,1))\n",
    "    else:\n",
    "        scalerX_transform = None\n",
    "        scalerY_transform = None\n",
    "    \n",
    "    ## TODO : Incase for feature selection\n",
    "        # ....\n",
    "        # ....\n",
    "        # ....\n",
    "\n",
    "    # Create train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(cluster_dataXX, cluster_dataYY, test_size=model_input.test_size, random_state=random_seed)\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    Y_train = np.transpose(Y_train) # IMP : Has to have only one row for GP training\n",
    "    Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "    Y_test = np.transpose(Y_test)\n",
    "    Y_test = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test, scalerX_transform, scalerY_transform\n",
    "\n",
    "def train_gp(X_train, X_test, Y_train, Y_test, model=None):\n",
    "    best_observed = []\n",
    "    # Finding best value in initial data\n",
    "    if model_input.maximization:\n",
    "        best_observed_value = Y_train.max()\n",
    "        optimal_solution = torch.cat([Y_train[0],Y_test[0]]).max()\n",
    "    else:\n",
    "        best_observed_value = Y_train.min()\n",
    "        optimal_solution = torch.cat([Y_train[0],Y_test[0]]).min()\n",
    "    \n",
    "    # If optimal value is present in the initial dataset sample remove it  \n",
    "    if (best_observed_value.eq(optimal_solution)) and model_input.maximization:\n",
    "        print('Max in training set, removing it before training models.')\n",
    "        optimal_position = torch.argmax(Y_train)\n",
    "        \n",
    "        # Add max value to test/exploration set\n",
    "        X_add_toTest = torch.reshape(X_train[optimal_position,:],(1,X_train.shape[1]))\n",
    "        X_test = torch.cat([X_test,X_add_toTest])\n",
    "        Y_add_toTest = torch.reshape(optimal_solution,(1,1))      \n",
    "        Y_test = torch.cat((Y_test,Y_add_toTest),1)\n",
    "        \n",
    "        # Remove max value from training set\n",
    "        X_train = X_train[torch.arange(0, X_train.shape[0]) != optimal_position, ...]\n",
    "        Y_train = Y_train[..., torch.arange(0, Y_train.shape[1]) != optimal_position]\n",
    "        \n",
    "        # Update best observed value\n",
    "        best_observed_value = Y_train.max()\n",
    "        \n",
    "    elif (best_observed_value.eq(optimal_solution)) and not model_input.maximization:\n",
    "        print('Min in training set, removing it before training models.')\n",
    "        optimal_position = torch.argmin(Y_train)\n",
    "        \n",
    "        # Add min value to test/exploration set\n",
    "        X_add_toTest = torch.reshape(X_train[optimal_position,:],(1,X_train.shape[1]))\n",
    "        X_test = torch.cat([X_test,X_add_toTest])\n",
    "        Y_add_toTest = torch.reshape(optimal_solution,(1,1))      \n",
    "        Y_test = torch.cat((Y_test,Y_add_toTest),1)\n",
    "        \n",
    "        # Remove min value from training set\n",
    "        X_train = X_train[torch.arange(0, X_train.shape[0]) != optimal_position, ...]\n",
    "        Y_train = Y_train[..., torch.arange(0, Y_train.shape[1]) != optimal_position]\n",
    "        \n",
    "        # Update best observed value\n",
    "        best_observed_value = Y_train.min()\n",
    "    \n",
    "    # Initialize data for training gp-0 and gp-l models\n",
    "    X_train0, Y_train0, X_test0, Y_test0 = X_train, Y_train, X_test, Y_test\n",
    "            \n",
    "    n_batch = model_input.n_batch_perTrial\n",
    "    \n",
    "    # Initialize likelihood, GP model and acquisition function for the models\n",
    "    #--------------------------- GP-0 ---------------------------#\n",
    "    likelihood_gp0 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    if model is None:\n",
    "        model_gp0 = surrogate_models.ExactGPModel(X_train0, Y_train0, likelihood_gp0) \n",
    "    else:\n",
    "        model_gp0 = model\n",
    "    AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_observed_value, maximize=model_input.maximization)\n",
    "    best_observed.append(best_observed_value)  # Appending to best_observed list for the given trial\n",
    "    \n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, n_batch + 1):\n",
    "        # Time start of iteration and end\n",
    "        t0 = time.monotonic()\n",
    "        if ((iteration-1)%model_input.n_update==0):\n",
    "            # fit the models every 10 iterations\n",
    "            model_gp0, likelihood_gp0 = surrogate_models.train_surrogate_gp0(X_train0, Y_train0)\n",
    "    \n",
    "        # optimize and get new observation using acquisition function\n",
    "        new_x0, new_y0, index, X_test_new0, Y_test_new0 = optimize_acqf_and_get_observation(AcqFunc_0, X_test0, Y_test0)\n",
    "        \n",
    "        # Update remaining choices tensor\n",
    "        X_test0 = X_test_new0\n",
    "        Y_test0 = Y_test_new0\n",
    "\n",
    "        # Update training points\n",
    "        X_train0 = torch.cat([X_train0, new_x0])\n",
    "        Y_train0 = torch.cat([Y_train0[0], new_y0[0]])\n",
    "        Y_train0 = torch.reshape(Y_train0,(1,Y_train0.shape[0]))\n",
    "\n",
    "        # update progress\n",
    "        if model_input.maximization:\n",
    "            best_value_ei0 = Y_train0.max()\n",
    "        elif not model_input.maximization:\n",
    "            best_value_ei0 = Y_train0.min()\n",
    "        best_observed.append(best_value_ei0)\n",
    "\n",
    "        # AcqFunc_0 = UpperConfidenceBound(model_gp0, beta=0.1) \n",
    "        AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_value_ei0, maximize=model_input.maximization)\n",
    "\n",
    "        # Time end of iteration\n",
    "        t1 = time.monotonic()\n",
    "    \n",
    "        if model_input.verbose:\n",
    "            print(\n",
    "                f\"\\nBatch {iteration:>2}: best_value (GP-0) = \",\n",
    "                f\"({best_value_ei0:>4.2f}\",\n",
    "                end=\"\",)\n",
    "            print(f'Iteration time = {t1-t0:>4.2f}.')\n",
    "\n",
    "    # t1 = time.monotonic()\n",
    "    # print(f\"time = {t1-t0:>4.2f}.\")\n",
    "\n",
    "    return best_observed, X_train0, X_test0, Y_train0, Y_test0, model_gp0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbf21d",
   "metadata": {},
   "source": [
    "#### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfb03e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------- Trial  1 of 1 --------------------\n",
      "\n",
      " -------------------- Cluster  0 of 1 --------------------\n",
      "tensor([[-0.4551, -0.0350, -1.0010,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch  1: best_value (GP-0) =  (2.59Iteration time = 174.28.\n",
      "tensor([[-0.4551, -0.0350, -0.7803,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch  2: best_value (GP-0) =  (2.59Iteration time = 6.89.\n",
      "tensor([[-0.8127, -0.0350, -1.0746,  1.2717, -0.0506, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch  3: best_value (GP-0) =  (2.59Iteration time = 6.38.\n",
      "tensor([[-0.5743, -0.0350, -0.7557,  1.0076,  0.1411, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch  4: best_value (GP-0) =  (2.59Iteration time = 6.33.\n",
      "tensor([[ 0.5988, -0.0350, -0.1180,  0.6776, -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch  5: best_value (GP-0) =  (2.59Iteration time = 6.28.\n",
      "tensor([[ 0.5988, -0.0350, -0.1180,  0.6776, -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch  6: best_value (GP-0) =  (2.59Iteration time = 6.38.\n",
      "tensor([[-0.3018, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch  7: best_value (GP-0) =  (2.59Iteration time = 6.49.\n",
      "tensor([[-0.3018, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch  8: best_value (GP-0) =  (2.59Iteration time = 6.32.\n",
      "tensor([[-0.3018, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch  9: best_value (GP-0) =  (2.59Iteration time = 6.61.\n",
      "tensor([[-0.3018, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 10: best_value (GP-0) =  (2.59Iteration time = 6.41.\n",
      "tensor([[-0.3018, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 11: best_value (GP-0) =  (2.59Iteration time = 6.28.\n",
      "tensor([[-0.3018, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 12: best_value (GP-0) =  (2.59Iteration time = 6.21.\n",
      "tensor([[-0.3018, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 13: best_value (GP-0) =  (2.59Iteration time = 6.39.\n",
      "tensor([[-0.4551, -0.0350, -1.0010,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 14: best_value (GP-0) =  (2.59Iteration time = 6.55.\n",
      "tensor([[-0.4551, -0.0350, -1.0010,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 15: best_value (GP-0) =  (2.59Iteration time = 6.53.\n",
      "tensor([[-0.4551, -0.0350, -1.0010,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 16: best_value (GP-0) =  (2.59Iteration time = 6.40.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717, -0.0506, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 17: best_value (GP-0) =  (2.59Iteration time = 6.39.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717, -0.0506, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 18: best_value (GP-0) =  (2.59Iteration time = 6.33.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717, -0.0506, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 19: best_value (GP-0) =  (2.59Iteration time = 6.33.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717, -0.0506, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 20: best_value (GP-0) =  (2.59Iteration time = 6.36.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717, -0.0506, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 21: best_value (GP-0) =  (2.59Iteration time = 170.42.\n",
      "tensor([[-0.7616, -0.0350, -1.2218,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 22: best_value (GP-0) =  (2.59Iteration time = 6.56.\n",
      "tensor([[-0.7233, -0.0350, -0.9458,  1.1232,  0.0213, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 23: best_value (GP-0) =  (2.59Iteration time = 6.50.\n",
      "tensor([[-0.7233, -0.0350, -0.9458,  1.1232,  0.0213, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 24: best_value (GP-0) =  (2.59Iteration time = 6.49.\n",
      "tensor([[-0.8383, -0.0350, -1.1114,  0.9746,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 25: best_value (GP-0) =  (2.59Iteration time = 6.64.\n",
      "tensor([[-0.9149, -0.0350, -0.8906,  0.9746,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 26: best_value (GP-0) =  (2.59Iteration time = 6.56.\n",
      "tensor([[-0.9149, -0.0350, -0.8906,  0.9746,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 27: best_value (GP-0) =  (2.59Iteration time = 6.62.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717,  0.5246, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 28: best_value (GP-0) =  (2.59Iteration time = 6.43.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717,  0.5246, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 29: best_value (GP-0) =  (2.59Iteration time = 6.32.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717,  0.5246, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 30: best_value (GP-0) =  (2.59Iteration time = 6.38.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717,  0.5246, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 31: best_value (GP-0) =  (2.59Iteration time = 6.38.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717,  0.5246, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 32: best_value (GP-0) =  (2.59Iteration time = 6.09.\n",
      "tensor([[-0.0974, -0.0350, -0.7067,  1.2717,  0.5246, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 33: best_value (GP-0) =  (2.59Iteration time = 5.88.\n",
      "tensor([[-0.4551, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 34: best_value (GP-0) =  (2.59Iteration time = 6.21.\n",
      "tensor([[-0.4551, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 35: best_value (GP-0) =  (2.59Iteration time = 6.16.\n",
      "tensor([[-0.4551, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 36: best_value (GP-0) =  (2.59Iteration time = 6.16.\n",
      "tensor([[-0.4551, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 37: best_value (GP-0) =  (2.59Iteration time = 6.15.\n",
      "tensor([[-0.4551, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 38: best_value (GP-0) =  (2.59Iteration time = 5.96.\n",
      "tensor([[-0.4551, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 39: best_value (GP-0) =  (2.59Iteration time = 5.99.\n",
      "tensor([[-0.4551, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 40: best_value (GP-0) =  (2.59Iteration time = 6.08.\n",
      "tensor([[-0.4551, -0.0350, -0.5595,  1.2717,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 41: best_value (GP-0) =  (2.59Iteration time = 137.45.\n",
      "tensor([[-0.6084, -0.0350, -0.7803,  1.5688,  0.6684, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 42: best_value (GP-0) =  (2.59Iteration time = 7.03.\n",
      "tensor([[-0.8127, -0.0350, -1.0746,  1.2717, -0.3382, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 43: best_value (GP-0) =  (2.59Iteration time = 7.27.\n",
      "tensor([[-0.4551, -0.0350, -0.7803,  1.8658,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 44: best_value (GP-0) =  (2.59Iteration time = 7.36.\n",
      "tensor([[-0.4551, -0.0350, -0.7803,  1.8658,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 45: best_value (GP-0) =  (2.59Iteration time = 7.34.\n",
      "tensor([[-0.4551, -0.0350, -0.7803,  1.8658,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 46: best_value (GP-0) =  (2.59Iteration time = 7.45.\n",
      "tensor([[-0.4551, -0.0350, -0.7803,  1.8658,  0.2370, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 47: best_value (GP-0) =  (2.59Iteration time = 7.51.\n",
      "tensor([[-0.2635, -0.0350, -0.6147,  1.5688,  0.0213, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 48: best_value (GP-0) =  (2.74Iteration time = 7.53.\n",
      "tensor([[-0.8383, -0.0350, -0.8906,  0.9746,  0.6684, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 49: best_value (GP-0) =  (2.74Iteration time = 7.45.\n",
      "tensor([[-0.3784, -0.0350, -1.1114,  0.6776,  0.6684, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 50: best_value (GP-0) =  (2.74Iteration time = 7.68.\n",
      "tensor([[-0.3784, -0.0350, -1.1114,  0.6776,  0.6684, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 51: best_value (GP-0) =  (2.74Iteration time = 7.49.\n",
      "tensor([[-1.1193, -0.0350, -1.1482,  0.8756, -0.0506, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 52: best_value (GP-0) =  (2.74Iteration time = 7.51.\n",
      "tensor([[-1.1193, -0.0350, -1.1482,  0.8756, -0.0506, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 53: best_value (GP-0) =  (2.74Iteration time = 7.36.\n",
      "tensor([[-0.8383, -0.0350, -1.2770,  1.1232,  0.6684, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 54: best_value (GP-0) =  (2.74Iteration time = 7.58.\n",
      "tensor([[-0.8383, -0.0350, -1.2770,  1.1232,  0.6684, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 55: best_value (GP-0) =  (2.74Iteration time = 7.30.\n",
      "tensor([[-0.8383, -0.0350, -1.2770,  1.1232,  0.6684, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 56: best_value (GP-0) =  (2.74Iteration time = 7.38.\n",
      "tensor([[-0.5062, -0.0350, -0.4123,  1.2717,  0.5246, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 57: best_value (GP-0) =  (2.74Iteration time = 7.21.\n",
      "tensor([[-0.5062, -0.0350, -0.4123,  1.2717,  0.5246, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 58: best_value (GP-0) =  (2.74Iteration time = 7.47.\n",
      "tensor([[-0.7233, -0.0350, -1.1114,  0.6776,  0.6684, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 59: best_value (GP-0) =  (2.74Iteration time = 7.58.\n",
      "tensor([[-0.7233, -0.0350, -1.1114,  0.6776,  0.6684, -0.0614, -0.1589]])\n",
      "tensor([[-0.1315, -0.0350,  0.3236,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.4380, -0.0350, -0.1670,  ..., -0.2423, -0.0614, -0.1589],\n",
      "        [-0.1485, -0.0350, -0.1180,  ...,  0.2370, -0.0614, -0.1589],\n",
      "        ...,\n",
      "        [-0.4551, -0.0350, -0.4859,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-0.7106, -0.0350, -0.7067,  ..., -0.6258, -0.0614, -0.1589],\n",
      "        [-1.0171, -0.0350, -0.9274,  ..., -0.6258, -0.0614, -0.1589]])\n",
      "tensor([[ 0.7023, -0.4456,  1.6468,  ..., -0.4606, -0.2699, -2.1043]])\n",
      "\n",
      "Batch 60: best_value (GP-0) =  (2.74Iteration time = 7.36.\n",
      "\n",
      "\n",
      "Starting the epsilon greedy search\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Create a new directory if it does not exist\n",
    "isExist = os.path.exists(model_input.output_folder)\n",
    "if not isExist:\n",
    "    os.makedirs(model_input.output_folder)\n",
    "    print(\"The new directory is created!\", model_input.output_folder)\n",
    "    \n",
    "# Commented out by NKT\n",
    "# # Copy input parameters file to output folder\n",
    "# shutil.copy2('surrogate_model_inputs.py',model_input.output_folder)\n",
    "# Copy surrogate model file to output folder\n",
    "shutil.copy2('surrogate_models.py',model_input.output_folder)\n",
    "\n",
    "# Training a single GP for test\n",
    "# a = train_gp(0)\n",
    "\n",
    "# # Train the cluster of GP models in a parallel for loop\n",
    "# best_observed_all_ei0 = Parallel(n_jobs=-1)(\n",
    "#     delayed(train_gp)(i) for i in range(num_cluster)\n",
    "# )\n",
    "\n",
    "# Train each GP model sequentially first then apply the epsilon greed algorithm\n",
    "for trial in range(1, model_input.n_trials + 1):\n",
    "    t0 = time.monotonic()\n",
    "    if model_input.random_seed == 'time':\n",
    "        random_seed = int(t0)\n",
    "    elif model_input.random_seed == 'iteration':\n",
    "        random_seed = trial\n",
    "\n",
    "    print(f\"\\n -------------------- Trial {trial:>2} of {model_input.n_trials} --------------------\\n\", end=\"\")\n",
    "\n",
    "    best_observed_all_clusters = []\n",
    "    X_train_all_clusters = []\n",
    "    X_test_all_clusters = []\n",
    "    Y_train_all_clusters = []\n",
    "    Y_test_all_clusters = []\n",
    "    model_gps_all_clusters = []\n",
    "\n",
    "    # Now train each GP model sequentially first \n",
    "    ## TODO : This part can be parallizable using joblib\n",
    "    for cluster_idx in range(num_cluster):\n",
    "        print(f\"\\n -------------------- Cluster {cluster_idx:>2} of {num_cluster} --------------------\\n\", end=\"\")\n",
    "        XX_desc = list(sample_dfs[cluster_idx].columns[:-1])\n",
    "        YY_desc = sample_dfs[cluster_idx].columns[-1]\n",
    "        # (\n",
    "        #     X_train,\n",
    "        #     X_test,\n",
    "        #     Y_train,\n",
    "        #     Y_test,\n",
    "        #     scalerX, \n",
    "        #     scalerY\n",
    "        # ) = create_train_test_data(sample_dfs[cluster_idx][XX_desc].to_numpy(), sample_dfs[cluster_idx][YY_desc].to_numpy(), random_seed)\n",
    "        X_train, X_test, Y_train, Y_test, scalerX_transform, scalerY_transform = create_train_test_data(clustered_dfs[cluster_idx][XX_desc].to_numpy(), clustered_dfs[cluster_idx][YY_desc].to_numpy(), random_seed)\n",
    "        dump(scalerX_transform, os.path.join(model_input.output_folder, f'scalerX_{cluster_idx}.joblib'))\n",
    "        dump(scalerY_transform, os.path.join(model_input.output_folder, f'scalerY_{cluster_idx}.joblib'))\n",
    "        (\n",
    "            best_observed_idx, \n",
    "            X_train_idx,\n",
    "            X_test_idx, \n",
    "            Y_train_idx, \n",
    "            Y_test_idx,\n",
    "            model_gp_idx\n",
    "        ) = train_gp(X_train, X_test, Y_train, Y_test)\n",
    "        best_observed_all_clusters.append(best_observed_idx)\n",
    "        X_train_all_clusters.append(X_train_idx)\n",
    "        X_test_all_clusters.append(X_test_idx)\n",
    "        Y_train_all_clusters.append(Y_train_idx)\n",
    "        Y_test_all_clusters.append(Y_test_idx)\n",
    "        model_gps_all_clusters.append(model_gp_idx)\n",
    "    \n",
    "    print(f'\\n')\n",
    "    print(f'Starting the epsilon greedy search')\n",
    "    print(f'\\n')\n",
    "\n",
    "    # # Now apply the epsilon greedy algorithm and choose which GP to train next\n",
    "    # for i in range(5):\n",
    "    #     random_number = np.random.rand()\n",
    "    #     epsilon = 0.1  # 10% exploration\n",
    "    #     # Explore using the Epsilon Greedy Exploration Strategy\n",
    "    #     if random_number <= epsilon:\n",
    "    #         # Selecting a number between 1,2 and 3\n",
    "    #         cluster_idx = np.random.choice(num_cluster)\n",
    "    #     else:\n",
    "    #         # Exploit best known action\n",
    "    #         cluster_idx = np.argmax([best_observed_all_clusters[i][-1] for i in range(num_cluster)])\n",
    "    #     print(f'Iteration {i} : Cluster {cluster_idx} is selected for training')\n",
    "    #     (\n",
    "    #         best_observed_idx,\n",
    "    #         X_train_idx, \n",
    "    #         X_test_idx,\n",
    "    #         Y_train_idx,\n",
    "    #         Y_test_idx,\n",
    "    #         model_gp_idx\n",
    "    #     ) = train_gp(X_train_all_clusters[cluster_idx], \\\n",
    "    #                 X_test_all_clusters[cluster_idx], \\\n",
    "    #                 Y_train_all_clusters[cluster_idx], \\\n",
    "    #                 Y_test_all_clusters[cluster_idx], \\\n",
    "    #                 model=model_gps_all_clusters[cluster_idx])\n",
    "        \n",
    "    #     best_observed_all_clusters[cluster_idx].extend(best_observed_idx)\n",
    "    #     X_train_all_clusters[cluster_idx] = X_train_idx\n",
    "    #     X_test_all_clusters[cluster_idx] = X_test_idx\n",
    "    #     Y_train_all_clusters[cluster_idx] = Y_train_idx\n",
    "    #     Y_test_all_clusters[cluster_idx] = Y_test_idx\n",
    "    #     model_gps_all_clusters[cluster_idx] = model_gp_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e1bd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the best value obtained vs number of iterations\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(num_cluster):\n",
    "    plt.plot(best_observed_all_clusters[i], label=f'Cluster {i}')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Best Value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fcc52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
