{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45452e9-567c-4658-bfa1-f9a6f6b70bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# This file costructs surrogate models for the input datasets\n",
    "import numpy as np   \n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "import sys\n",
    "\n",
    "# Torch specific module imports\n",
    "import torch\n",
    "import gpytorch \n",
    "\n",
    "# botorch specific modules\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from botorch.optim import optimize_acqf, optimize_acqf_discrete\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.acquisition.monte_carlo import (\n",
    "    qExpectedImprovement,\n",
    "    qNoisyExpectedImprovement,\n",
    ")\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.acquisition import UpperConfidenceBound, ExpectedImprovement\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Tick parameters\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['xtick.major.size'] = 5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.size'] = 5\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.size'] = 5\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.size'] = 5\n",
    "plt.rcParams['ytick.minor.width'] = 1\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 15\n",
    "\n",
    "# User defined python classes and files\n",
    "import input_class \n",
    "import code_inputs as model_input\n",
    "import utils_dataset as utilsd\n",
    "import surrogate_models\n",
    "import kmeans as km\n",
    "\n",
    "# Set the random seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Perform input checks\n",
    "if model_input.N_SEARCH == 0:\n",
    "    raise ValueError('Number of searches cannot be 0')\n",
    "\n",
    "if model_input.NUM_CLUSTER == 1:\n",
    "    n_batch_per_search = int(model_input.N_BATCH_PER_TRIAL)\n",
    "else:\n",
    "    n_batch_per_search = int(model_input.N_BATCH_PER_TRIAL/model_input.N_SEARCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b29bdc5",
   "metadata": {},
   "source": [
    "#### K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8de62ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num carbon</th>\n",
       "      <th>num fluorine</th>\n",
       "      <th>num hydrogen</th>\n",
       "      <th>num nitrogen</th>\n",
       "      <th>num oxygen</th>\n",
       "      <th>num sulfur</th>\n",
       "      <th>num silicon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69835</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69836</th>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69837</th>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69838</th>\n",
       "      <td>1888</td>\n",
       "      <td>0</td>\n",
       "      <td>1152</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69839</th>\n",
       "      <td>536</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69840 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num carbon  num fluorine  num hydrogen  num nitrogen  num oxygen  \\\n",
       "0             360             0           216           144          72   \n",
       "1             360             0           216           144         144   \n",
       "2             432             0           360           144          72   \n",
       "3             360             0           144           216         216   \n",
       "4             360             0           144           216         216   \n",
       "...           ...           ...           ...           ...         ...   \n",
       "69835         996             0           576            96           0   \n",
       "69836        1020             0           576            48           0   \n",
       "69837        1360             0           768            64           0   \n",
       "69838        1888             0          1152           128         128   \n",
       "69839         536             0           288            32           0   \n",
       "\n",
       "       num sulfur  num silicon  \n",
       "0               0            0  \n",
       "1               0            0  \n",
       "2               0            0  \n",
       "3               0            0  \n",
       "4               0            0  \n",
       "...           ...          ...  \n",
       "69835           0            0  \n",
       "69836           0            0  \n",
       "69837           0            0  \n",
       "69838           0            0  \n",
       "69839           0            0  \n",
       "\n",
       "[69840 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input = input_class.inputs(input_path='../datasets/')\n",
    "XX_prop, YY, descriptors = Input.read_inputs()\n",
    "XX_comp_df, YY_df = Input.get_comp()\n",
    "XX_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe95ea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num carbon</th>\n",
       "      <th>num fluorine</th>\n",
       "      <th>num hydrogen</th>\n",
       "      <th>num nitrogen</th>\n",
       "      <th>num oxygen</th>\n",
       "      <th>num sulfur</th>\n",
       "      <th>num silicon</th>\n",
       "      <th>deliverable capacity [v STP/v]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "      <td>448</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.565439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1152</td>\n",
       "      <td>0</td>\n",
       "      <td>832</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152.524690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1376</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.996501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>720</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143.024802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1088</td>\n",
       "      <td>0</td>\n",
       "      <td>768</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153.528996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69835</th>\n",
       "      <td>1536</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.196985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69836</th>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>1368</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>137.095297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69837</th>\n",
       "      <td>2560</td>\n",
       "      <td>0</td>\n",
       "      <td>1536</td>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169.809763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69838</th>\n",
       "      <td>2784</td>\n",
       "      <td>0</td>\n",
       "      <td>1824</td>\n",
       "      <td>576</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.963253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69839</th>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>1200</td>\n",
       "      <td>96</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.323232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69840 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num carbon  num fluorine  num hydrogen  num nitrogen  num oxygen  \\\n",
       "0             832             0           448           384           0   \n",
       "1            1152             0           832           128          64   \n",
       "2            1376             0           896           256          64   \n",
       "3             864             0           720           192           0   \n",
       "4            1088             0           768           128           0   \n",
       "...           ...           ...           ...           ...         ...   \n",
       "69835        1536             0           960           160           0   \n",
       "69836        1440             0          1368           216           0   \n",
       "69837        2560             0          1536           384         384   \n",
       "69838        2784             0          1824           576          96   \n",
       "69839        1920             0          1200            96          48   \n",
       "\n",
       "       num sulfur  num silicon  deliverable capacity [v STP/v]  \n",
       "0               0            0                      165.565439  \n",
       "1               0            0                      152.524690  \n",
       "2               0            0                      115.996501  \n",
       "3               0            0                      143.024802  \n",
       "4               0            0                      153.528996  \n",
       "...           ...          ...                             ...  \n",
       "69835           0            0                      110.196985  \n",
       "69836           0           36                      137.095297  \n",
       "69837           0            0                      169.809763  \n",
       "69838           0            0                      110.963253  \n",
       "69839           0            0                      166.323232  \n",
       "\n",
       "[69840 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_dfs = km.k_means(XX_comp_df, YY_df, model_input.NUM_CLUSTER)\n",
    "sample_dfs = km.draw_samples(clustered_dfs, sample_fraction = 1.00)\n",
    "samples = km.concat(sample_dfs)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed4601",
   "metadata": {},
   "source": [
    "#### Acquisition function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955bc734-96c5-4d3a-9325-920c041e256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: TO BE Check\n",
    "bounds = torch.tensor([[-10.0], [12.0]])\n",
    "\n",
    "batch_size = 1\n",
    "num_restarts= 10 \n",
    "raw_samples = 512\n",
    "\n",
    "def optimize_acqf_and_get_observation(acq_func, X_test, Y_test, iteration):\n",
    "    \"\"\"Optimizes the acquisition function, and returns a new candidate\"\"\"\n",
    "\n",
    "    candidates, _ = optimize_acqf_discrete(\n",
    "        acq_function=acq_func,\n",
    "        choices=X_test,\n",
    "        q=batch_size,\n",
    "        max_batch_size=2048,\n",
    "        num_restarts=num_restarts,\n",
    "        raw_samples=raw_samples,  # used for intialization heuristic\n",
    "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
    "        unique=True\n",
    "    )\n",
    "    \n",
    "    print(f'\\nBatch {iteration:>2}: Selected Candidate = {candidates}')\n",
    "    # observe new values\n",
    "    new_x = candidates.detach()\n",
    "    b = [1 if torch.all(X_test[i].eq(new_x)) else 0 for i in range(0,X_test.shape[0]) ]\n",
    "    b = torch.tensor(b).to(torch.int)\n",
    "    index = b.nonzero()[0][0]\n",
    "    new_y = torch.reshape(Y_test[0,index],(1,1))\n",
    "    \n",
    "    X_test_new = X_test[torch.arange(0, X_test.shape[0]) != index, ...]\n",
    "    Y_test_new = Y_test[..., torch.arange(0, Y_test.shape[1]) != index]\n",
    "    \n",
    "    return new_x, new_y, index, X_test_new, Y_test_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93f668d",
   "metadata": {},
   "source": [
    "#### GP Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72bb9112-1749-44fd-bc9d-7c0edb2e59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(cluster_dataXX, cluster_dataYY, random_seed):\n",
    "    if model_input.STANDARDIZE:\n",
    "        cluster_dataXX, scalerX_transform = utilsd.standardize_data(cluster_dataXX)\n",
    "        cluster_dataYY, scalerY_transform = utilsd.standardize_data(cluster_dataYY.reshape(-1,1))\n",
    "    else:\n",
    "        scalerX_transform = None\n",
    "        scalerY_transform = None\n",
    "    \n",
    "    ## TODO : Incase for feature selection\n",
    "        # ....\n",
    "        # ....\n",
    "        # ....\n",
    "\n",
    "    # Create train and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(cluster_dataXX, cluster_dataYY, test_size=model_input.TEST_SIZE, random_state=random_seed)\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    Y_train = np.transpose(Y_train) # IMP : Has to have only one row for GP training\n",
    "    Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
    "    Y_test = np.transpose(Y_test)\n",
    "    Y_test = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test, scalerX_transform, scalerY_transform\n",
    "\n",
    "def train_gp(X_train, X_test, Y_train, Y_test, model=None):\n",
    "    best_observed = []\n",
    "    # Finding best value in initial data\n",
    "    if model_input.MAXIMIZATION:\n",
    "        best_observed_value = Y_train.max()\n",
    "        optimal_solution = torch.cat([Y_train[0],Y_test[0]]).max()\n",
    "    else:\n",
    "        best_observed_value = Y_train.min()\n",
    "        optimal_solution = torch.cat([Y_train[0],Y_test[0]]).min()\n",
    "    \n",
    "    # If optimal value is present in the initial dataset sample remove it  \n",
    "    if (best_observed_value.eq(optimal_solution)) and model_input.MAXIMIZATION:\n",
    "        print('Max in training set, removing it before training models.')\n",
    "        optimal_position = torch.argmax(Y_train)\n",
    "        \n",
    "        # Add max value to test/exploration set\n",
    "        X_add_toTest = torch.reshape(X_train[optimal_position,:],(1,X_train.shape[1]))\n",
    "        X_test = torch.cat([X_test,X_add_toTest])\n",
    "        Y_add_toTest = torch.reshape(optimal_solution,(1,1))      \n",
    "        Y_test = torch.cat((Y_test,Y_add_toTest),1)\n",
    "        \n",
    "        # Remove max value from training set\n",
    "        X_train = X_train[torch.arange(0, X_train.shape[0]) != optimal_position, ...]\n",
    "        Y_train = Y_train[..., torch.arange(0, Y_train.shape[1]) != optimal_position]\n",
    "        \n",
    "        # Update best observed value\n",
    "        best_observed_value = Y_train.max()\n",
    "        \n",
    "    elif (best_observed_value.eq(optimal_solution)) and not model_input.MAXIMIZATION:\n",
    "        print('Min in training set, removing it before training models.')\n",
    "        optimal_position = torch.argmin(Y_train)\n",
    "        \n",
    "        # Add min value to test/exploration set\n",
    "        X_add_toTest = torch.reshape(X_train[optimal_position,:],(1,X_train.shape[1]))\n",
    "        X_test = torch.cat([X_test,X_add_toTest])\n",
    "        Y_add_toTest = torch.reshape(optimal_solution,(1,1))      \n",
    "        Y_test = torch.cat((Y_test,Y_add_toTest),1)\n",
    "        \n",
    "        # Remove min value from training set\n",
    "        X_train = X_train[torch.arange(0, X_train.shape[0]) != optimal_position, ...]\n",
    "        Y_train = Y_train[..., torch.arange(0, Y_train.shape[1]) != optimal_position]\n",
    "        \n",
    "        # Update best observed value\n",
    "        best_observed_value = Y_train.min()\n",
    "    \n",
    "    # Initialize data for training gp-0 and gp-l models\n",
    "    X_train0, Y_train0, X_test0, Y_test0 = X_train, Y_train, X_test, Y_test\n",
    "    \n",
    "    # Initialize likelihood, GP model and acquisition function for the models\n",
    "    #--------------------------- GP-0 ---------------------------#\n",
    "    likelihood_gp0 = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    if model is None:\n",
    "        model_gp0 = surrogate_models.ExactGPModel(X_train0, Y_train0, likelihood_gp0) \n",
    "    else:\n",
    "        model_gp0 = model\n",
    "    AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_observed_value, maximize=model_input.MAXIMIZATION)\n",
    "    best_observed.append(best_observed_value.item())  # Appending to best_observed list for the given trial\n",
    "    \n",
    "    # run N_BATCH rounds of BayesOpt after the initial random batch\n",
    "    for iteration in range(1, n_batch_per_search + 1):\n",
    "        # Time start of iteration and end\n",
    "        t0 = time.monotonic()\n",
    "  \n",
    "        if (model_input.N_UPDATE !=0) and ((iteration-1)%model_input.N_UPDATE==0):\n",
    "            # fit the models every 10 iterations\n",
    "            model_gp0, likelihood_gp0 = surrogate_models.train_surrogate_gp0(X_train0, Y_train0)\n",
    "    \n",
    "        # optimize and get new observation using acquisition function\n",
    "        new_x0, new_y0, index, X_test_new0, Y_test_new0 = optimize_acqf_and_get_observation(AcqFunc_0, X_test0, Y_test0, iteration)\n",
    "        \n",
    "        # Update remaining choices tensor\n",
    "        X_test0 = X_test_new0\n",
    "        Y_test0 = Y_test_new0\n",
    "\n",
    "        # Update training points\n",
    "        X_train0 = torch.cat([X_train0, new_x0])\n",
    "        Y_train0 = torch.cat([Y_train0[0], new_y0[0]])\n",
    "        Y_train0 = torch.reshape(Y_train0,(1,Y_train0.shape[0]))\n",
    "\n",
    "        # update progress\n",
    "        if model_input.MAXIMIZATION:\n",
    "            best_value_ei0 = Y_train0.max()\n",
    "        elif not model_input.MAXIMIZATION:\n",
    "            best_value_ei0 = Y_train0.min()\n",
    "        best_observed.append(best_value_ei0.item())\n",
    "\n",
    "        # AcqFunc_0 = UpperConfidenceBound(model_gp0, beta=0.1) \n",
    "        AcqFunc_0 = ExpectedImprovement(model=model_gp0, best_f=best_value_ei0, maximize=model_input.MAXIMIZATION)\n",
    "\n",
    "        # Time end of iteration\n",
    "        t1 = time.monotonic()\n",
    "    \n",
    "        if model_input.VERBOSE:\n",
    "            print(\n",
    "                f\"Batch {iteration:>2}: best_value (GP-0) = \",\n",
    "                f\"{best_value_ei0.item():>4.2f}\",\n",
    "                end=\"\",)\n",
    "            print(f'\\nBatch {iteration:>2}: Iteration time = {t1-t0:>4.2f}.')\n",
    "\n",
    "    return [best_observed, X_train0, X_test0, Y_train0, Y_test0, model_gp0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fbf21d",
   "metadata": {},
   "source": [
    "#### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb03e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created! /Users/nikhilthota/Desktop/lab/projects/SPIRAL/codes_and_datasets/T-NIKHIL/project-localGPs_for_COF/bo_output/results_with_three_clusters/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m     search_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexploiting\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : Cluster \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcluster_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is selected for training (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 102\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_all_clusters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m                \u001b[49m\u001b[43mX_test_all_clusters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m                \u001b[49m\u001b[43mY_train_all_clusters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                \u001b[49m\u001b[43mY_test_all_clusters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_gps_all_clusters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcluster_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Add the best values\u001b[39;00m\n\u001b[1;32m    109\u001b[0m best_observed_all_clusters[cluster_idx]\u001b[38;5;241m.\u001b[39mextend(results[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 95\u001b[0m, in \u001b[0;36mtrain_gp\u001b[0;34m(X_train, X_test, Y_train, Y_test, model)\u001b[0m\n\u001b[1;32m     92\u001b[0m     model_gp0, likelihood_gp0 \u001b[38;5;241m=\u001b[39m surrogate_models\u001b[38;5;241m.\u001b[39mtrain_surrogate_gp0(X_train0, Y_train0)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# optimize and get new observation using acquisition function\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m new_x0, new_y0, index, X_test_new0, Y_test_new0 \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf_and_get_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAcqFunc_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Update remaining choices tensor\u001b[39;00m\n\u001b[1;32m     98\u001b[0m X_test0 \u001b[38;5;241m=\u001b[39m X_test_new0\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36moptimize_acqf_and_get_observation\u001b[0;34m(acq_func, X_test, Y_test, iteration)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize_acqf_and_get_observation\u001b[39m(acq_func, X_test, Y_test, iteration):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimizes the acquisition function, and returns a new candidate\"\"\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     candidates, _ \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf_discrete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchoices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_restarts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# used for intialization heuristic\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43munique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Selected Candidate = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcandidates\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# observe new values\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/botorch/optim/optimize.py:1087\u001b[0m, in \u001b[0;36moptimize_acqf_discrete\u001b[0;34m(acq_function, q, choices, max_batch_size, unique, **kwargs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m candidates, torch\u001b[38;5;241m.\u001b[39mstack(acq_value_list)\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 1087\u001b[0m     acq_values \u001b[38;5;241m=\u001b[39m \u001b[43m_split_batch_eval_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoices_batched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batch_size\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m best_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(acq_values)\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m choices_batched[best_idx], acq_values[best_idx]\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/botorch/optim/optimize.py:1097\u001b[0m, in \u001b[0;36m_split_batch_eval_acqf\u001b[0;34m(acq_function, X, max_batch_size)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split_batch_eval_acqf\u001b[39m(\n\u001b[1;32m   1095\u001b[0m     acq_function: AcquisitionFunction, X: Tensor, max_batch_size: \u001b[38;5;28mint\u001b[39m\n\u001b[1;32m   1096\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43macq_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X_ \u001b[38;5;129;01min\u001b[39;00m X\u001b[38;5;241m.\u001b[39msplit(max_batch_size)])\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/botorch/utils/transforms.py:259\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# add t-batch dim\u001b[39;00m\n\u001b[1;32m    258\u001b[0m X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 259\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(acqf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_ensemble(acqf\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# IDEA: this could be wrapped into SampleReducingMCAcquisitionFunction\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    263\u001b[0m         output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m acqf\u001b[38;5;241m.\u001b[39m_log \u001b[38;5;28;01melse\u001b[39;00m logmeanexp(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    264\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/botorch/acquisition/analytic.py:355\u001b[0m, in \u001b[0;36mExpectedImprovement.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;129m@t_batch_mode_transform\u001b[39m(expected_q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    343\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate Expected Improvement on the candidate set X.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m        given design points `X`.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     mean, sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean_and_sigma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     u \u001b[38;5;241m=\u001b[39m _scaled_improvement(mean, sigma, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaximize)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sigma \u001b[38;5;241m*\u001b[39m _ei_helper(u)\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/botorch/acquisition/analytic.py:106\u001b[0m, in \u001b[0;36mAnalyticAcquisitionFunction._mean_and_sigma\u001b[0;34m(self, X, compute_sigma, min_var)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the first and second moments of the model posterior.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    returns a single tensor of means if compute_sigma is True.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# ensures buffers / parameters are on the same device\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m posterior \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposterior_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_transform\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m mean \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# removing redundant dimensions\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m compute_sigma:\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/botorch/models/gpytorch.py:183\u001b[0m, in \u001b[0;36mGPyTorchModel.posterior\u001b[0;34m(self, X, observation_noise, posterior_transform, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_inputs(X)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gpt_posterior_settings():\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# NOTE: BoTorch's GPyTorchModels also inherit from GPyTorch's ExactGP, thus\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# self(X) calls GPyTorch's ExactGP's __call__, which computes the posterior,\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# rather than e.g. SingleTaskGP's forward, which computes the prior.\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     mvn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observation_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_noise, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;66;03m# TODO: Make sure observation noise is transformed correctly\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/gpytorch/models/exact_gp.py:333\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Make the prediction\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mcg_tolerance(settings\u001b[38;5;241m.\u001b[39meval_cg_tolerance\u001b[38;5;241m.\u001b[39mvalue()):\n\u001b[1;32m    330\u001b[0m     (\n\u001b[1;32m    331\u001b[0m         predictive_mean,\n\u001b[1;32m    332\u001b[0m         predictive_covar,\n\u001b[0;32m--> 333\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[1;32m    336\u001b[0m predictive_mean \u001b[38;5;241m=\u001b[39m predictive_mean\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39mtest_shape)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/gpytorch/models/exact_prediction_strategies.py:290\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    285\u001b[0m     test_test_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :]\n\u001b[1;32m    286\u001b[0m     test_train_covar \u001b[38;5;241m=\u001b[39m joint_covar[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train]\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexact_predictive_mean(test_mean, test_train_covar),\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexact_predictive_covar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_test_covar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_covar\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    291\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/gpytorch/models/exact_prediction_strategies.py:357\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_predictive_covar\u001b[0;34m(self, test_test_covar, test_train_covar)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m test_test_covar \u001b[38;5;241m+\u001b[39m MatmulLinearOperator(test_train_covar, covar_correction_rhs\u001b[38;5;241m.\u001b[39mmul(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    356\u001b[0m precomputed_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovar_cache\n\u001b[0;32m--> 357\u001b[0m covar_inv_quad_form_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exact_predictive_covar_inv_quad_form_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecomputed_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_train_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(test_test_covar):\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m to_linear_operator(\n\u001b[1;32m    360\u001b[0m         torch\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    361\u001b[0m             test_test_covar, covar_inv_quad_form_root \u001b[38;5;241m@\u001b[39m covar_inv_quad_form_root\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    362\u001b[0m         )\n\u001b[1;32m    363\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/bo-hackathon/lib/python3.12/site-packages/gpytorch/models/exact_prediction_strategies.py:116\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy._exact_predictive_covar_inv_quad_form_root\u001b[0;34m(self, precomputed_cache, test_train_covar)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mComputes :math:`K_{X^{*}X} S` given a precomputed cache\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03mWhere :math:`S` is a tensor such that :math:`SS^{\\top} = (K_{XX} + \\sigma^2 I)^{-1}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :obj:`~linear_operator.operators.LinearOperator`: :math:`K_{X^{*}X} S`\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Here the precomputed cache represents S,\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# where S S^T = (K_XX + sigma^2 I)^-1\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtest_train_covar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecomputed_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Create a new directory if it does not exist\n",
    "isExist = os.path.exists(model_input.OUT_FOLDER)\n",
    "if not isExist:\n",
    "    os.makedirs(model_input.OUT_FOLDER)\n",
    "    print(\"The new directory is created!\", model_input.OUT_FOLDER)\n",
    "\n",
    "shutil.copy2('surrogate_models.py',model_input.OUT_FOLDER)\n",
    "\n",
    "# Send the print statements to a log file in the model output folder\n",
    "print_file_path = model_input.OUT_FOLDER + 'log.txt'\n",
    "sys.stdout = open(print_file_path, 'w')\n",
    "\n",
    "# Train each GP model sequentially first then apply the epsilon greed algorithm\n",
    "for trial in range(1, model_input.N_TRIALS + 1):\n",
    "    # Make a folder to save all trial data\n",
    "    os.makedirs(model_input.OUT_FOLDER + f'/trial_{trial}', exist_ok=True)\n",
    "\n",
    "    t0 = time.monotonic()\n",
    "    if model_input.RANDOM_SEED == 'time':\n",
    "        random_seed = int(t0)\n",
    "    elif model_input.RANDOM_SEED == 'iteration':\n",
    "        random_seed = trial\n",
    "\n",
    "    print(f\"\\n -------------------- Trial {trial:>2} of {model_input.N_TRIALS} --------------------\\n\", end=\"\")\n",
    "\n",
    "    # Currently these are saved as np arrays at the end of the trial to the respective model output folder.\n",
    "    best_observed_all_clusters = []\n",
    "    X_train_all_clusters = []\n",
    "    X_test_all_clusters = []\n",
    "    Y_train_all_clusters = []\n",
    "    Y_test_all_clusters = []\n",
    "    model_gps_all_clusters = []\n",
    "\n",
    "    # Creating the initial training and test sets for each cluster\n",
    "    for cluster_idx in range(model_input.NUM_CLUSTER):\n",
    "        XX_desc = list(sample_dfs[cluster_idx].columns[:-1])\n",
    "        YY_desc = sample_dfs[cluster_idx].columns[-1]\n",
    "        (\n",
    "            X_train_idx,\n",
    "            X_test_idx,\n",
    "            Y_train_idx,\n",
    "            Y_test_idx,\n",
    "            scalerX, \n",
    "            scalerY\n",
    "        ) = create_train_test_data(sample_dfs[cluster_idx][XX_desc].to_numpy(), sample_dfs[cluster_idx][YY_desc].to_numpy(), random_seed)\n",
    "        dump(scalerX, os.path.join(model_input.OUT_FOLDER + f'/trial_{trial}', f'scalerX_{cluster_idx + 1}.joblib'))\n",
    "        dump(scalerY, os.path.join(model_input.OUT_FOLDER + f'/trial_{trial}', f'scalerY_{cluster_idx + 1}.joblib'))\n",
    "        best_observed_all_clusters.append(None)\n",
    "        X_train_all_clusters.append(X_train_idx)\n",
    "        X_test_all_clusters.append(X_test_idx)\n",
    "        Y_train_all_clusters.append(Y_train_idx)\n",
    "        Y_test_all_clusters.append(Y_test_idx)\n",
    "        model_gps_all_clusters.append(None)\n",
    "    \n",
    "    if model_input.NUM_CLUSTER > 1:\n",
    "        print(f'\\n')\n",
    "        print(f'Starting the initial search (training all local GPs.)')\n",
    "        print(f'\\n')  \n",
    "\n",
    "    # Initially training of GPs done in parallel by using joblib\n",
    "    if model_input.TRAIN_PARALLEL:\n",
    "        results_cluster_0, results_cluster_1, results_cluster_2 = Parallel(n_jobs=-1)(delayed(train_gp)(X_train_all_clusters[i], X_test_all_clusters[i], Y_train_all_clusters[i], Y_test_all_clusters[i]) for i in range(model_input.NUM_CLUSTER))\n",
    "        results_all_clusters = [results_cluster_0, results_cluster_1, results_cluster_2]\n",
    "    else:\n",
    "        results_all_clusters = []\n",
    "        for i in range(model_input.NUM_CLUSTER):\n",
    "            print(f\"\\n -------------------- Cluster {i + 1:>2} of {model_input.NUM_CLUSTER} --------------------\\n\", end=\"\")\n",
    "            results_all_clusters.append(train_gp(X_train_all_clusters[i], X_test_all_clusters[i], Y_train_all_clusters[i], Y_test_all_clusters[i]))\n",
    "\n",
    "    for i, results_i_cluster in enumerate(results_all_clusters):\n",
    "        best_observed_all_clusters[i] = results_i_cluster[0] \n",
    "        X_train_all_clusters[i] = results_i_cluster[1]\n",
    "        X_test_all_clusters[i] = results_i_cluster[2]\n",
    "        Y_train_all_clusters[i] = results_i_cluster[3]\n",
    "        Y_test_all_clusters[i] = results_i_cluster[4]\n",
    "        model_gps_all_clusters[i] = results_i_cluster[5] \n",
    "\n",
    "    # Do the epsilon greedy search only if number of clusters is greater than 1\n",
    "    if (model_input.N_SEARCH > 1) and (model_input.NUM_CLUSTER > 1):\n",
    "        print(f'\\n')\n",
    "        print(f'Starting the epsilon greedy search (choosing which local GP to train next.)')\n",
    "        print(f'\\n')    \n",
    "\n",
    "        # Now apply the epsilon greedy algorithm and choose which GP to train next\n",
    "        # Subtracting 1 from the number of searches as the first search is already done\n",
    "        for i in range(model_input.N_SEARCH - 1):\n",
    "            random_number = np.random.rand()\n",
    "            epsilon = model_input.EPSILON\n",
    "            # Explore using the Epsilon Greedy Exploration Strategy\n",
    "            if random_number <= epsilon:\n",
    "                # Selecting a number between 1,2 and 3\n",
    "                cluster_idx = np.random.choice(range(model_input.NUM_CLUSTER))\n",
    "                search_text = 'exploring'\n",
    "            else:\n",
    "                # Exploit best known action\n",
    "                cluster_idx = np.argmax([best_observed_all_clusters[k][-1] for k in range(model_input.NUM_CLUSTER)])\n",
    "                search_text = 'exploiting'\n",
    "            print(f'\\nIteration {i} : Cluster {cluster_idx + 1} is selected for training ({search_text})')\n",
    "            results = train_gp(X_train_all_clusters[cluster_idx], \\\n",
    "                            X_test_all_clusters[cluster_idx], \\\n",
    "                            Y_train_all_clusters[cluster_idx], \\\n",
    "                            Y_test_all_clusters[cluster_idx], \\\n",
    "                            model=model_gps_all_clusters[cluster_idx])\n",
    "            \n",
    "            # Add the best values\n",
    "            best_observed_all_clusters[cluster_idx].extend(results[0])\n",
    "            # For the reamaining clusters, extend the last best value\n",
    "            for j in range(model_input.NUM_CLUSTER):\n",
    "                if j != cluster_idx:\n",
    "                    best_observed_all_clusters[j].extend( list( np.ones((len(results[0]),))*best_observed_all_clusters[j][-1] ) )\n",
    "            X_train_all_clusters[cluster_idx] = results[1]\n",
    "            X_test_all_clusters[cluster_idx] = results[2]\n",
    "            Y_train_all_clusters[cluster_idx] = results[3]\n",
    "            Y_test_all_clusters[cluster_idx] = results[4]\n",
    "            model_gps_all_clusters[cluster_idx] = results[5]\n",
    "    \n",
    "    print(f'<----------- Search completed for trial {trial} ---------->\\n')\n",
    "\n",
    "    # Save the numpy arrays\n",
    "\n",
    "    if model_input.NUM_CLUSTER > 1:\n",
    "        filesave_name = 'all_clusters'\n",
    "    else:\n",
    "        filesave_name = 'one_cluster'\n",
    "    dump(best_observed_all_clusters, os.path.join(model_input.OUT_FOLDER + f'/trial_{trial}', f'best_observed_{filesave_name}.joblib'))\n",
    "    dump(X_train_all_clusters, os.path.join(model_input.OUT_FOLDER + f'/trial_{trial}', f'X_train_{filesave_name}.joblib'))\n",
    "    dump(X_test_all_clusters, os.path.join(model_input.OUT_FOLDER + f'/trial_{trial}', f'X_test_{filesave_name}.joblib'))\n",
    "    dump(Y_train_all_clusters, os.path.join(model_input.OUT_FOLDER + f'/trial_{trial}', f'Y_train_{filesave_name}.joblib'))\n",
    "    dump(Y_test_all_clusters, os.path.join(model_input.OUT_FOLDER + f'/trial_{trial}', f'Y_test_{filesave_name}.joblib'))\n",
    "    dump(model_gps_all_clusters, os.path.join(model_input.OUT_FOLDER + f'/trial_{trial}', f'model_gp_{filesave_name}.joblib'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6623d178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 306)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_observed_all_clusters_all_trials = []\n",
    "for trial in range(1,5):\n",
    "    # Load files from the trial\n",
    "    path = f'../bo_output/results_with_three_clusters/trial_{trial}'\n",
    "    # Load the joblib files\n",
    "    best_observed_all_clusters_all_trials.append(load(os.path.join(path, 'best_observed_all_clusters.joblib')))\n",
    "\n",
    "# Convert to a 3D numpy array\n",
    "best_observed_all_clusters_all_trials = np.array(best_observed_all_clusters_all_trials)\n",
    "best_observed_all_clusters_all_trials.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "321e5285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of Iteration')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_best_observed = []\n",
    "std_best_observed = []\n",
    "\n",
    "for i in range(3):\n",
    "    mean_best_observed.append(np.mean(best_observed_all_clusters_all_trials[:][i][:], axis=0))\n",
    "    std_best_observed.append(np.std(best_observed_all_clusters_all_trials[:][i][:], axis=0))\n",
    "\n",
    "# Plot the mean and standard deviation of the best observed values\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(3):\n",
    "    plt.plot(mean_best_observed[i], label=f'Cluster {i+1}')\n",
    "    plt.fill_between(range(len(mean_best_observed[i])), mean_best_observed[i] - std_best_observed[i], mean_best_observed[i] + std_best_observed[i], alpha=0.2)\n",
    "plt.xlabel('Number of Iteration')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
